Create a Company Policy Chatbot with RAG, Pinecone Vector Database, and OpenAI

https://n8nworkflows.xyz/workflows/create-a-company-policy-chatbot-with-rag--pinecone-vector-database--and-openai-7563


# Create a Company Policy Chatbot with RAG, Pinecone Vector Database, and OpenAI

### 1. Workflow Overview

This workflow implements a **Company Policy Chatbot** based on Retrieval-Augmented Generation (RAG) using Pinecone as a vector database and OpenAI’s GPT models. It is designed to automatically ingest company policy documents from Google Drive, index them into Pinecone after chunking and embedding, and then respond to user chat queries with accurate, concise information extracted from those documents.

The workflow is logically divided into two main blocks:

- **1.1 Data Ingestion and Vector Store Update**  
  This block monitors a specific Google Drive folder for new or updated policy documents, downloads them, processes the documents by splitting them into chunks, embeds the chunks using OpenAI embeddings, and inserts the vectorized data into the Pinecone vector store.

- **1.2 Chat Query Handling and AI Response**  
  This block triggers on user chat messages, invokes an AI agent to process the query, retrieves relevant information from the Pinecone vector store through a Vector Store QnA tool, and responds with concise, factual answers generated by a GPT-4o-mini model.

---

### 2. Block-by-Block Analysis

#### 2.1 Data Ingestion and Vector Store Update

- **Overview:**  
  Watches a Google Drive folder for newly created or updated files, downloads the files, processes them using a PDF loader and recursive character text splitter, then embeds and inserts the processed chunks into the Pinecone vector store for later retrieval.

- **Nodes Involved:**  
  - Google Drive Trigger  
  - Google Drive  
  - Default Data Loader  
  - Recursive Character Text Splitter  
  - OpenAI Embeddings  
  - PineconeVectorStore

- **Node Details:**

  1. **Google Drive Trigger**  
     - *Type & Role:* Trigger node that polls Google Drive every minute to detect new files in a specific folder.  
     - *Config:* Watches folder with ID `18ElQ-fxK0zXX5Ahx1lk80OXnAJ9NwvHl`.  
     - *Input:* None (trigger node)  
     - *Output:* File metadata on new file creation event.  
     - *Failure modes:* API rate limits, auth token expiration.  
     - *Notes:* Poll interval set to every minute for near-real-time updates.

  2. **Google Drive**  
     - *Type & Role:* Downloads the latest file triggered by the above node.  
     - *Config:* Downloads file with dynamic ID from trigger output.  
     - *Input:* File metadata from Google Drive Trigger.  
     - *Output:* Binary file content for downstream processing.  
     - *Failure modes:* Download failures, file permission issues.

  3. **Default Data Loader**  
     - *Type & Role:* Loads document content from binary PDF data.  
     - *Config:* Uses built-in PDF loader, inputs binary data.  
     - *Input:* Binary file from Google Drive node.  
     - *Output:* Extracted text document.  
     - *Failure modes:* Corrupt PDF files or unsupported formats.

  4. **Recursive Character Text Splitter**  
     - *Type & Role:* Splits loaded document into smaller chunks suitable for embedding.  
     - *Config:* Uses markdown split code, 50 character overlap between chunks for context retention.  
     - *Input:* Document text from Default Data Loader.  
     - *Output:* Array of text chunks.  
     - *Failure modes:* Excessive chunking or incorrect splitting if document structure varies.

  5. **OpenAI Embeddings**  
     - *Type & Role:* Converts text chunks into vector embeddings using OpenAI API.  
     - *Config:* Batch size 512, embedding dimension 512.  
     - *Input:* Text chunks.  
     - *Output:* Embedding vectors.  
     - *Credentials:* OpenAI API key configured.  
     - *Failure modes:* API quota limits, network errors, invalid input format.

  6. **PineconeVectorStore**  
     - *Type & Role:* Inserts the vector embeddings into the Pinecone index under a specified namespace.  
     - *Config:* Insert mode, namespace placeholder `[YouNameSpace]`, index `n8ntest`.  
     - *Input:* Embeddings from OpenAI Embeddings node.  
     - *Output:* Confirmation of insertion.  
     - *Credentials:* Pinecone API key configured.  
     - *Failure modes:* Index not found, auth errors, namespace misconfiguration.

- **Sticky Note:**  
  > **Data Loader**  
  > - Google Drive Trigger polls folder every minute for changes.  
  > - Google Drive node downloads latest files.  
  > - Pinecone Vector Store node stores processed document chunks after splitting.

---

#### 2.2 Chat Query Handling and AI Response

- **Overview:**  
  Listens to incoming user chat messages, passes the query to an AI agent configured with a system prompt specialized in retrieving and answering policy questions via Pinecone vector store. The AI agent uses a Vector Store QnA tool to fetch relevant documents, processes the information with OpenAI’s GPT-4o-mini model, and returns concise, factual answers.

- **Nodes Involved:**  
  - When chat message received  
  - AI Agent  
  - OpenAI Chat Model  
  - Simple Memory  
  - Pinecone Vector Store  
  - Vector Store QnA  
  - OpenAI Chat Model2  
  - Calculator (optional tool)

- **Node Details:**

  1. **When chat message received**  
     - *Type & Role:* Webhook trigger for incoming chat messages.  
     - *Config:* Public webhook ID for external chat clients.  
     - *Input:* User chat query.  
     - *Output:* Query text to AI Agent.  
     - *Failure modes:* Webhook connectivity, request validation errors.

  2. **AI Agent**  
     - *Type & Role:* Core AI orchestration node that manages memory, tools, and language model.  
     - *Config:* System message instructs to answer precisely using Pinecone vector store data only, output structured and concise.  
     - *Input:* Chat query from webhook.  
     - *Output:* AI-generated answer.  
     - *Connections:* Uses Simple Memory for context, Vector Store QnA tool, OpenAI Chat Model for language generation, and Calculator tool for numeric operations if needed.  
     - *Failure modes:* Expression errors, API timeouts, tool failures.

  3. **OpenAI Chat Model**  
     - *Type & Role:* Language model node running GPT-4o-mini.  
     - *Config:* Model `gpt-4o-mini`, connected as AI Agent’s language model.  
     - *Credentials:* OpenAI API.  
     - *Input:* Prompt from AI Agent.  
     - *Output:* Generated text.  
     - *Failure modes:* API rate limits, network issues.

  4. **Simple Memory**  
     - *Type & Role:* Buffer window memory to maintain conversational context for AI Agent.  
     - *Config:* Default parameters (no explicit memory size configured).  
     - *Input/Output:* Stores previous chat turns.  
     - *Failure modes:* Memory overflow or loss if node reset.

  5. **Pinecone Vector Store**  
     - *Type & Role:* Query interface to Pinecone index.  
     - *Config:* Namespace placeholder `<yourNameSpace>`, index `n8ntest`.  
     - *Credentials:* Pinecone API.  
     - *Input:* Incoming text query from Vector Store QnA tool.  
     - *Output:* Retrieved relevant documents.  
     - *Failure modes:* Query failures, auth errors.

  6. **Vector Store QnA**  
     - *Type & Role:* Tool node that wraps querying Pinecone and providing documents to AI Agent.  
     - *Config:* Description notes it returns documents related to company policies.  
     - *Input:* Query from AI Agent.  
     - *Output:* Documents passed back to AI Agent.  
     - *Failure modes:* Query returning no docs, misconfigurations.

  7. **OpenAI Chat Model2**  
     - *Type & Role:* Secondary GPT-4o-mini node connected to Vector Store QnA.  
     - *Config:* Same model as main OpenAI Chat Model, used for document summarization or answer refinement.  
     - *Credentials:* OpenAI API.  
     - *Failure modes:* Same as other OpenAI nodes.

  8. **Calculator**  
     - *Type & Role:* Tool for performing calculations if needed by AI Agent.  
     - *Config:* Default.  
     - *Input/Output:* Invoked by AI Agent only if calculations are required.  
     - *Failure modes:* Misinterpretation of input.

- **Sticky Note:**  
  > **Data Retrieval**  
  > AI Agent connects to Vector Store QnA tool to fetch relevant info from Pinecone, then processes and returns answers via AI language model.

---

### 3. Summary Table

| Node Name                 | Node Type                                    | Functional Role                            | Input Node(s)                    | Output Node(s)                | Sticky Note                                                                                   |
|---------------------------|----------------------------------------------|-------------------------------------------|---------------------------------|------------------------------|----------------------------------------------------------------------------------------------|
| Google Drive Trigger       | n8n-nodes-base.googleDriveTrigger            | Trigger on new/updated files in GDrive    | None                            | Google Drive                  | Data Loader: Polls Google Drive folder every minute                                          |
| Google Drive              | n8n-nodes-base.googleDrive                    | Downloads triggered file                   | Google Drive Trigger            | PineconeVectorStore           | Data Loader: Downloads latest changes                                                       |
| Default Data Loader        | @n8n/n8n-nodes-langchain.documentDefaultDataLoader | Loads file content as text document        | Recursive Character Text Splitter| PineconeVectorStore           | Data Loader: Uses PDF loader                                                                |
| Recursive Character Text Splitter | @n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter | Splits text document into chunks           | Default Data Loader             | OpenAI Embeddings             | Data Loader: Splits document with overlap                                                  |
| OpenAI Embeddings         | @n8n/n8n-nodes-langchain.embeddingsOpenAi    | Creates vector embeddings from chunks     | Recursive Character Text Splitter| PineconeVectorStore           | Data Loader: Embeds document chunks                                                        |
| PineconeVectorStore       | @n8n/n8n-nodes-langchain.vectorStorePinecone | Inserts embeddings into Pinecone index    | OpenAI Embeddings              | None                         | Data Loader: Stores vectorized document chunks                                              |
| When chat message received | @n8n/n8n-nodes-langchain.chatTrigger          | Trigger on incoming chat messages          | None                            | AI Agent                     | Data Retrieval: Starts user query flow                                                     |
| AI Agent                  | @n8n/n8n-nodes-langchain.agent                | Orchestrates AI tools and memory           | When chat message received      | Calculator, Vector Store QnA, Simple Memory, OpenAI Chat Model | Data Retrieval: Central AI orchestrator                                                    |
| Simple Memory             | @n8n/n8n-nodes-langchain.memoryBufferWindow  | Maintains conversation context             | AI Agent                      | AI Agent                     | Data Retrieval: Stores chat history                                                        |
| Pinecone Vector Store     | @n8n/n8n-nodes-langchain.vectorStorePinecone | Queries Pinecone vector database            | Vector Store QnA                | Vector Store QnA             | Data Retrieval: Fetches relevant documents                                                  |
| Vector Store QnA          | @n8n/n8n-nodes-langchain.toolVectorStore     | Retrieves documents from Pinecone           | AI Agent                      | AI Agent                     | Data Retrieval: Returns policy documents                                                   |
| OpenAI Chat Model         | @n8n/n8n-nodes-langchain.lmChatOpenAi         | Language model for AI Agent                  | AI Agent                      | AI Agent                     | Data Retrieval: Generates AI answers                                                       |
| OpenAI Chat Model2        | @n8n/n8n-nodes-langchain.lmChatOpenAi         | Language model for Vector Store QnA tool    | Vector Store QnA               | Vector Store QnA             | Data Retrieval: Summarizes or refines responses                                            |
| Calculator                | @n8n/n8n-nodes-langchain.toolCalculator       | Performs calculations when requested        | AI Agent                      | AI Agent                     | Data Retrieval: Optional tool for numeric calculations                                     |
| Sticky Note               | n8n-nodes-base.stickyNote                      | Documentation                              | None                            | None                         | Data Loader: Explains file ingestion and storage flow                                      |
| Sticky Note1              | n8n-nodes-base.stickyNote                      | Documentation                              | None                            | None                         | Data Retrieval: Explains AI agent and vector store query flow                              |

---

### 4. Reproducing the Workflow from Scratch

1. **Create Google Drive Trigger node**  
   - Type: Google Drive Trigger  
   - Operation: Trigger on file created events  
   - Poll interval: Every minute  
   - Folder to watch: Specify folder ID (e.g., `18ElQ-fxK0zXX5Ahx1lk80OXnAJ9NwvHl`)  
   - Credentials: Connect Google Drive OAuth2 credential

2. **Add Google Drive node**  
   - Type: Google Drive  
   - Operation: Download  
   - File ID: Use dynamic input from Google Drive Trigger node  
   - Credentials: Same Google Drive OAuth2 credential  
   - Connect Google Drive Trigger → Google Drive

3. **Add Default Data Loader node**  
   - Type: Document Default Data Loader  
   - Loader: PDF Loader  
   - Input: Binary data from Google Drive node  
   - Connect Google Drive → Default Data Loader

4. **Add Recursive Character Text Splitter node**  
   - Type: Recursive Character Text Splitter  
   - Split code: markdown  
   - Chunk overlap: 50 characters  
   - Connect Default Data Loader → Recursive Character Text Splitter

5. **Add OpenAI Embeddings node**  
   - Type: Embeddings OpenAI  
   - Batch size: 512  
   - Dimensions: 512  
   - Credentials: OpenAI API key  
   - Connect Recursive Character Text Splitter → OpenAI Embeddings

6. **Add PineconeVectorStore node**  
   - Type: Vector Store Pinecone  
   - Mode: Insert  
   - Pinecone Index: Select or create index (e.g., `n8ntest`)  
   - Namespace: Your namespace string (replace placeholder)  
   - Credentials: Pinecone API key  
   - Connect OpenAI Embeddings → PineconeVectorStore

7. **Create When chat message received node**  
   - Type: Langchain Chat Trigger  
   - Public: true (to allow external access)  
   - Connect to next node: AI Agent

8. **Create AI Agent node**  
   - Type: Langchain Agent  
   - System message: Provide specialized prompt instructing to answer using Pinecone vector store only, concise and factual  
   - Connect When chat message received → AI Agent

9. **Create Simple Memory node**  
   - Type: Memory Buffer Window  
   - Default settings  
   - Connect Simple Memory → AI Agent (ai_memory input)

10. **Create Pinecone Vector Store node**  
    - Type: Vector Store Pinecone  
    - Namespace and index same as ingestion step  
    - Credentials: Pinecone API  
    - Connect Pinecone Vector Store → Vector Store QnA (ai_vectorStore input)

11. **Create Vector Store QnA node**  
    - Type: Tool Vector Store  
    - Description: Returns documents related to company policies  
    - Connect AI Agent → Vector Store QnA (ai_tool input)  
    - Connect Vector Store QnA → AI Agent (ai_tool output)

12. **Create OpenAI Chat Model node**  
    - Type: LM Chat OpenAI  
    - Model: `gpt-4o-mini`  
    - Credentials: OpenAI API  
    - Connect AI Agent → OpenAI Chat Model (ai_languageModel input)  
    - Connect OpenAI Chat Model → AI Agent (ai_languageModel output)

13. **Create OpenAI Chat Model2 node**  
    - Duplicate of OpenAI Chat Model node  
    - Connect Vector Store QnA → OpenAI Chat Model2 (ai_languageModel input)  
    - Connect OpenAI Chat Model2 → Vector Store QnA (ai_languageModel output)

14. **Create Calculator node**  
    - Type: Tool Calculator  
    - Connect AI Agent → Calculator (ai_tool input)  
    - Connect Calculator → AI Agent (ai_tool output)  
    - Optional: used when AI needs calculations

15. **Link all nodes as per connections described**  
    - Ensure AI Agent connects to memory, vector store, tools, and language models appropriately.

16. **Configure credentials**  
    - OpenAI API key for embeddings and chat models  
    - Pinecone API key for vector store operations  
    - Google Drive OAuth2 credentials for file access

17. **Test end-to-end**  
    - Upload PDF files to watched Google Drive folder  
    - Confirm ingestion and insertion into Pinecone  
    - Send chat messages to webhook URL and verify AI responses

---

### 5. General Notes & Resources

| Note Content                                                                                                                       | Context or Link                                         |
|-----------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------|
| System message for AI Agent instructs to answer only with information from vector store documents and to be concise and factual.  | Critical for correct AI behavior                         |
| Pinecone namespaces and indexes must be consistently configured between ingestion and query nodes.                                | Configuration consistency                                |
| Google Drive folder ID must be accessible by the connected Google Drive account with appropriate permissions.                    | Folder watching setup                                   |
| OpenAI GPT model used is `gpt-4o-mini` for optimized performance and cost efficiency.                                              | Model choice in chat nodes                               |
| Polling interval set to every minute to balance update latency and API quota usage.                                                | Google Drive Trigger configuration                       |
| Workflow is designed to be extensible with additional tools (e.g., Calculator) that can be invoked by the AI agent.               | Extensibility and modularity                             |
| Reference documentation: [n8n Langchain Nodes](https://docs.n8n.io/nodes/n8n-nodes-langchain/)                                     | Official n8n documentation for Langchain nodes          |
| Pinecone documentation: [https://www.pinecone.io/docs/](https://www.pinecone.io/docs/)                                             | For index and namespace management                       |
| OpenAI API docs: [https://platform.openai.com/docs/](https://platform.openai.com/docs/)                                            | For embedding and chat model API configuration           |

---

**Disclaimer:** The text provided is derived exclusively from an automated workflow created using n8n, a tool for integration and automation. This process strictly complies with current content policies and contains no illegal, offensive, or protected elements. All data handled is legal and public.