{"user_name":"Tihomir Mateev","user_username":"tishun","user_bio":"Software engineer @ Redis Inc.","user_links":"https://github.com/tishun","user_avatar":"https://gravatar.com/avatar/bcda49f11ec27667f90627f99d1f5c097941073511482dc3c580c04c1bcdf612?r=pg&d=retro&size=200","url":"https://n8nworkflows.xyz/workflows/reduce-llm-costs-with-semantic-caching-using-redis-vector-store-and-huggingface-10887\n","url_n8n":"https://n8n.io/workflows/10887","nodeTypes":{"n8n-nodes-base.if":{"count":1},"n8n-nodes-base.code":{"count":1},"n8n-nodes-base.stickyNote":{"count":3},"@n8n/n8n-nodes-langchain.chat":{"count":2},"@n8n/n8n-nodes-langchain.agent":{"count":1},"@n8n/n8n-nodes-langchain.chatTrigger":{"count":1},"@n8n/n8n-nodes-langchain.lmChatOpenAi":{"count":1},"@n8n/n8n-nodes-langchain.memoryRedisChat":{"count":1},"@n8n/n8n-nodes-langchain.vectorStoreRedis":{"count":2},"@n8n/n8n-nodes-langchain.documentDefaultDataLoader":{"count":1},"@n8n/n8n-nodes-langchain.embeddingsHuggingFaceInference":{"count":2},"@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter":{"count":1}},"categories":[{"id":5,"name":"Engineering"},{"id":47,"name":"AI Chatbot"}]}