Generate BigQuery SQL from Natural Language Queries using GPT-4o Chat

https://n8nworkflows.xyz/workflows/generate-bigquery-sql-from-natural-language-queries-using-gpt-4o-chat-6745


# Generate BigQuery SQL from Natural Language Queries using GPT-4o Chat

### 1. Workflow Overview

This workflow enables users to generate valid BigQuery SQL queries from natural language questions using the GPT-4o Chat model. It is designed for interactive, chat-based querying of a BigQuery dataset. The workflow extracts schema information dynamically, formats it for AI consumption, and leverages a LangChain AI Agent to produce SQL queries strictly constrained to the available schema. Queries generated by the AI are then executed against BigQuery, and results or error messages are returned to the user.

**Target Use Cases:**  
- Business analysts or data scientists querying BigQuery without SQL expertise  
- Embedding natural language query interfaces into dashboards or chatbots  
- Validating AI-generated SQL strictly based on dataset schema to reduce errors

**Logical Blocks:**  
- **1.1 Input Reception:** Receives user questions via an embedded chat trigger, initializes session memory.  
- **1.2 Schema Retrieval & Preparation:** Queries BigQuery INFORMATION_SCHEMA for tables and columns, aggregates and formats schema info into text.  
- **1.3 AI Query Generation:** Provides user question and schema text to an AI agent which generates a structured SQL query JSON output.  
- **1.4 SQL Execution & Error Handling:** Runs the AI-generated query on BigQuery, continues on errors, and prompts user for alternate queries if execution fails.  
- **1.5 Memory Buffer:** Maintains conversational context per user session to support multi-turn interactions.

---

### 2. Block-by-Block Analysis

#### 2.1 Input Reception

**Overview:**  
This block captures the user’s natural language question via a chat interface and initializes session-specific memory for context retention.

**Nodes Involved:**  
- Embedable chat for users to ask questions of bigquery  
- Simple Memory

**Node Details:**  

- **Embedable chat for users to ask questions of bigquery**  
  - Type: LangChain Chat Trigger  
  - Role: Entry point; listens for user chat input and triggers workflow execution  
  - Configuration: Default options, webhook enabled for receiving chat messages  
  - Input: HTTP webhook POST with user question and sessionId  
  - Output: JSON with `chatInput` (user question) and `sessionId`  
  - Edge Cases: Missing or malformed input; webhook failures  

- **Simple Memory**  
  - Type: LangChain Memory Buffer Window  
  - Role: Maintains conversational context per session  
  - Configuration: Uses dynamic sessionKey based on incoming chat's `sessionId` for individualized memory  
  - Input: Triggered by chat node output  
  - Output: Context passed into AI agent for multi-turn conversation  
  - Edge Cases: SessionKey missing or changed; memory overflow or reset  

---

#### 2.2 Schema Retrieval & Preparation

**Overview:**  
Fetches all tables, columns, and their data types from BigQuery’s INFORMATION_SCHEMA, aggregates them, and converts the schema data into a single text string suitable for inclusion in AI prompts.

**Nodes Involved:**  
- Output all table, and column names in your schema  
- Combine into one field  
- Convert table names and columns into single text for agent

**Node Details:**  

- **Output all table, and column names in your schema**  
  - Type: Google BigQuery  
  - Role: Queries INFORMATION_SCHEMA.COLUMNS for table and column metadata  
  - Configuration: SQL query selecting `table_name`, `column_name`, `data_type` from a fixed schema path (replaceable by user)  
  - Credentials: Google BigQuery OAuth2 Service Account JSON  
  - Input: Triggered by chat input node  
  - Output: List of rows with schema metadata  
  - Edge Cases: Permission errors, invalid project/dataset, empty schema results  

- **Combine into one field**  
  - Type: Aggregate  
  - Role: Aggregates all rows into a single JSON array to prepare for text conversion  
  - Configuration: Aggregate all item data (no grouping)  
  - Input: BigQuery schema query output  
  - Output: Single aggregated item containing all schema rows  
  - Edge Cases: No rows to aggregate (empty schema)  

- **Convert table names and columns into single text for agent**  
  - Type: Code  
  - Role: Converts aggregated JSON schema into a newline-separated string of JSON objects  
  - Configuration: Custom JavaScript that JSON-stringifies each schema row and joins by newline  
  - Input: Aggregated schema data  
  - Output: Single JSON object with a `text` field containing the schema as newline-separated JSON strings  
  - Edge Cases: JSON conversion errors, malformed schema data  

---

#### 2.3 AI Query Generation

**Overview:**  
Combines the user question with the formatted schema text and sends it to a LangChain AI Agent leveraging GPT-4o Chat to return a strictly formatted JSON containing the SQL query.

**Nodes Involved:**  
- combine the table names with user question  
- OpenAI Chat Model  
- Simple Memory (linked here as memory source)  
- Structured Output Parser  
- AI Agent - Write SQL Query

**Node Details:**  

- **combine the table names with user question**  
  - Type: Merge (combine mode)  
  - Role: Merges the user question and schema text into one input for the AI agent  
  - Configuration: Combine mode, combining all inputs into one JSON object  
  - Input: Two inputs — user question from chat and schema text from code node  
  - Output: Combined JSON with both question and schema text  
  - Edge Cases: Mismatched input lengths; missing data  

- **OpenAI Chat Model**  
  - Type: LangChain OpenAI Chat Model  
  - Role: Provides the underlying GPT-4o language model for the AI Agent  
  - Configuration: Model set to "gpt-4o", no additional options  
  - Credentials: OpenAI API key required  
  - Input: Connected internally within AI Agent node  
  - Output: Raw AI model responses  
  - Edge Cases: API authentication errors, rate limits, model unavailability, network timeouts  

- **Simple Memory**  
  - (Previously described, connected as AI memory source here)  

- **Structured Output Parser**  
  - Type: LangChain Structured Output Parser  
  - Role: Enforces AI output to conform to specified JSON schema with a single key `query`  
  - Configuration: JSON schema example with key `"query"` expecting SQL query string only  
  - Input: AI Agent raw output  
  - Output: Parsed JSON with extracted SQL query  
  - Edge Cases: AI outputs not matching schema, parse failures  

- **AI Agent - Write SQL Query**  
  - Type: LangChain Agent  
  - Role: Core AI agent combining user input, schema, memory, language model, and output parser to produce SQL query  
  - Configuration:  
    - System message defines strict instructions: must produce valid BigQuery SQL using only schema-provided tables/columns, output JSON only, no extra text  
    - Prompt combines user question and schema text  
    - Output parser attached for structured JSON  
    - Uses GPT-4o model and session memory for multi-turn context  
  - Input: Combined merged input, memory, model, and parser  
  - Output: JSON with SQL query string  
  - Edge Cases: AI hallucinations, schema mismatch, incomplete queries, output parser failures  

---

#### 2.4 SQL Execution & Error Handling

**Overview:**  
Executes the AI-generated SQL query on BigQuery, handles errors gracefully, and prompts the user to try another question if the query execution fails.

**Nodes Involved:**  
- Run query against schema  
- Ask User to try another question

**Node Details:**  

- **Run query against schema**  
  - Type: Google BigQuery  
  - Role: Executes the SQL query generated by AI against the user’s BigQuery dataset  
  - Configuration:  
    - Project ID selected from list  
    - SQL Query set dynamically from AI Agent output `{{ $json.output.query }}`  
  - Credentials: Google BigQuery OAuth2  
  - Input: SQL query JSON from AI Agent  
  - Output: Query results or error  
  - Error Handling: Continues on error output to next node  
  - Edge Cases: Syntax errors in SQL, permission denied, query timeout, empty result set  

- **Ask User to try another question**  
  - Type: Code  
  - Role: Returns a JSON message prompting user to retry if the query failed  
  - Configuration: Static JSON message: "That query didn't work. Try another question."  
  - Input: Error branch from BigQuery execution node  
  - Output: JSON message for UI or chatbot  
  - Edge Cases: None functional, always returns message  

---

#### 2.5 User Guidance & Documentation

**Overview:**  
Sticky Notes provide user instructions, setup details, and contact information for support.

**Nodes Involved:**  
- Sticky Note  
- Sticky Note1

**Node Details:**  

- **Sticky Note**  
  - Type: Sticky Note  
  - Role: Display branding and contact info  
  - Content:  
    - Title: "Talk-to-Data: Instant BigQuery SQL Generator"  
    - Contact: LinkedIn link and email address  
  - Edge Cases: None  

- **Sticky Note1**  
  - Type: Sticky Note  
  - Role: Setup instructions for importing workflow, configuring credentials, updating queries, and testing  
  - Content Summary:  
    - Step-by-step setup guide with links and example SQL for schema fetching  
    - Credential creation instructions for OpenAI and Google BigQuery  
    - Guidance on testing and activation  
  - Edge Cases: Instructions require manual adherence; users must replace placeholder project/dataset names  

---

### 3. Summary Table

| Node Name                               | Node Type                                  | Functional Role                            | Input Node(s)                                               | Output Node(s)                           | Sticky Note                                                                                                                                            |
|----------------------------------------|--------------------------------------------|--------------------------------------------|-------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| Embedable chat for users to ask questions of bigquery | LangChain Chat Trigger                      | Entry point for user question input         | None                                                        | Output all table, and column names in your schema, combine the table names with user question | See Sticky Note1 for setup instructions                                                                                                               |
| Output all table, and column names in your schema | Google BigQuery                            | Fetch schema metadata from BigQuery         | Embedable chat for users to ask questions of bigquery        | Combine into one field                   | See Sticky Note1 for setup instructions                                                                                                               |
| Combine into one field                  | Aggregate                                  | Aggregate schema rows into single object    | Output all table, and column names in your schema             | Convert table names and columns into single text for agent |                                                                                                                                                        |
| Convert table names and columns into single text for agent | Code                                     | Convert aggregated schema to text format    | Combine into one field                                        | combine the table names with user question |                                                                                                                                                        |
| combine the table names with user question | Merge                                     | Combine user question and schema text       | Embedable chat for users to ask questions of bigquery, Convert table names and columns into single text for agent | AI Agent - Write SQL Query              |                                                                                                                                                        |
| Simple Memory                          | LangChain Memory Buffer Window             | Maintain session memory for multi-turn chat | Embedable chat for users to ask questions of bigquery        | AI Agent - Write SQL Query               |                                                                                                                                                        |
| OpenAI Chat Model                     | LangChain OpenAI Chat Model                 | Language model for AI Agent                  | Internal to AI Agent                                          | AI Agent - Write SQL Query               | Requires OpenAI API key (see Sticky Note1)                                                                                                            |
| Structured Output Parser              | LangChain Structured Output Parser          | Parse AI output into structured JSON        | AI Agent - Write SQL Query                                    | AI Agent - Write SQL Query (final output) |                                                                                                                                                        |
| AI Agent - Write SQL Query            | LangChain Agent                            | Generate BigQuery SQL query from input       | combine the table names with user question, Simple Memory, OpenAI Chat Model, Structured Output Parser | Run query against schema                 |                                                                                                                                                        |
| Run query against schema              | Google BigQuery                            | Execute AI-generated SQL query               | AI Agent - Write SQL Query                                    | Ask User to try another question (on error) | Requires Google BigQuery OAuth2 (see Sticky Note1)                                                                                                    |
| Ask User to try another question      | Code                                       | Return error message if query fails          | Run query against schema (error output)                       | None                                    |                                                                                                                                                        |
| Sticky Note                          | Sticky Note                                | Branding and contact info                     | None                                                        | None                                    | Contact: LinkedIn https://www.linkedin.com/in/robertbreen, Email: rbreen@ynteractive.com                                                               |
| Sticky Note1                         | Sticky Note                                | Setup instructions and usage guide           | None                                                        | None                                    | Setup instructions include credential creation and query customization (see details in section 2.5)                                                     |

---

### 4. Reproducing the Workflow from Scratch

1. **Create Chat Trigger Node**  
   - Node Type: LangChain Chat Trigger  
   - Name: "Embedable chat for users to ask questions of bigquery"  
   - Configure webhook to receive chat inputs with fields `chatInput` and `sessionId`  

2. **Create BigQuery Node to Fetch Schema**  
   - Node Type: Google BigQuery  
   - Name: "Output all table, and column names in your schema"  
   - Set SQL Query:  
     ```sql
     SELECT table_name, column_name, data_type
     FROM `YOUR_PROJECT.YOUR_DATASET.INFORMATION_SCHEMA.COLUMNS`
     ```  
   - Set Project ID accordingly  
   - Attach Google BigQuery OAuth2 credentials  

3. **Create Aggregate Node**  
   - Node Type: Aggregate  
   - Name: "Combine into one field"  
   - Set mode to aggregate all item data without grouping  

4. **Create Code Node to Convert Schema to Text**  
   - Node Type: Code  
   - Name: "Convert table names and columns into single text for agent"  
   - Use JavaScript code:  
     ```javascript
     return [
       {
         json: {
           text: items.map(item => JSON.stringify(item.json)).join('\n'),
         },
       },
     ];
     ```  

5. **Create Merge Node to Combine User Question and Schema Text**  
   - Node Type: Merge  
   - Name: "combine the table names with user question"  
   - Set mode to "combine" all inputs  

6. **Create LangChain OpenAI Chat Model Node**  
   - Node Type: LangChain OpenAI Chat Model  
   - Name: "OpenAI Chat Model"  
   - Select GPT-4o model  
   - Assign OpenAI API credentials  

7. **Create LangChain Memory Node**  
   - Node Type: LangChain Memory Buffer Window  
   - Name: "Simple Memory"  
   - Use expression `={{ $('Embedable chat for users to ask questions of bigquery').item.json.sessionId }}` as sessionKey  
   - Set sessionIdType to customKey  

8. **Create LangChain Structured Output Parser Node**  
   - Node Type: LangChain Structured Output Parser  
   - Name: "Structured Output Parser"  
   - Provide JSON schema example:  
     ```json
     {
       "query": "sql query and no other text"
     }
     ```  

9. **Create LangChain Agent Node**  
   - Node Type: LangChain Agent  
   - Name: "AI Agent - Write SQL Query"  
   - Set promptType to "define"  
   - Set system message:  
     ```
     You are a helpful AI assistant that writes valid SQL queries for Google BigQuery.

     You will be given:
     - A user’s question,
     - A list of available table names and column names.

     Your task is to:
     1. Write a syntactically correct BigQuery SQL query that best answers the user's question,
     2. Only use table and column names that appear in the provided schema — do not guess or invent names,
     3. Return your output in a strict JSON format with one key: "query".

     ⚠️ Do NOT invent table or column names.
     ⚠️ If a relevant field does not exist, make the best effort to answer with what's available, or omit that part.
     ⚠️ Do NOT include any explanation, notes, or comments — only the final JSON.

     --- 

     **this schema must be written before the table name  Schema:**

     `YOUR_PROJECT.YOUR_DATASET.`

     output data in json like this. 
     {
       "query": "sql query and no other text"
     }
     ```
   - Enable output parser and connect it to the Structured Output Parser  
   - Connect memory node and OpenAI Chat Model node as AI memory and AI language model respectively  

10. **Create BigQuery Node to Execute SQL**  
    - Node Type: Google BigQuery  
    - Name: "Run query against schema"  
    - Set SQL Query to dynamic value: `{{ $json.output.query }}`  
    - Assign BigQuery OAuth2 credentials  
    - Set project ID accordingly  
    - Set onError to continue to next node  

11. **Create Code Node for Error Prompt**  
    - Node Type: Code  
    - Name: "Ask User to try another question"  
    - JavaScript code:  
      ```javascript
      return [
        {
          json: {
            message: "That query didn't work. Try another question."
          }
        }
      ];
      ```  

12. **Connect Nodes:**  
    - Chat Trigger → BigQuery schema fetch  
    - BigQuery schema fetch → Aggregate node  
    - Aggregate node → Code node (convert schema to text)  
    - Code node → Merge node (input 2)  
    - Chat Trigger → Merge node (input 1)  
    - Merge node → AI Agent  
    - AI Agent → BigQuery execution node  
    - BigQuery execution node → on success: end or output results  
    - BigQuery execution node → on error: Code node with error prompt  

13. **Create Sticky Notes:**  
    - Add sticky notes with branding and detailed setup instructions as per original content  

---

### 5. General Notes & Resources

| Note Content                                                                                                   | Context or Link                                                    |
|---------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|
| Talk-to-Data: Instant BigQuery SQL Generator                                                                  | Branding and workflow title                                       |
| Setup instructions include importing workflow, adding OpenAI and Google BigQuery credentials, and query updates | See Sticky Note1 content in workflow                             |
| Contact Robert Breen on LinkedIn: https://www.linkedin.com/in/robertbreen                                       | Provided in Sticky Note                                           |
| Email contact for support: rbreen@ynteractive.com                                                              | Provided in Sticky Note                                           |
| Use BigQuery INFORMATION_SCHEMA.COLUMNS for schema fetching                                                    | Standard BigQuery metadata query                                  |
| AI prompt enforces strict JSON output with key "query"                                                        | Ensures compatibility with SQL execution node                    |
| Replace placeholder project and dataset names in SQL query and AI prompt                                       | Critical for correct schema querying and SQL execution           |
| OpenAI GPT-4o model requires valid API key                                                                    | Obtain from https://platform.openai.com                           |
| Google BigQuery OAuth2 credentials require a Service Account JSON key with appropriate BigQuery permissions    | Obtain from Google Cloud Console → IAM & Admin → Service Accounts|

---

**Disclaimer:**  
The provided text is exclusively derived from an n8n-automated workflow. It strictly complies with current content policies, containing no illegal, offensive, or protected elements. All data handled is legal and publicly accessible.