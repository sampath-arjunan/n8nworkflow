Automatically Scrape Make.com Job Board with GPT-5-mini Summaries & Email Digest

https://n8nworkflows.xyz/workflows/automatically-scrape-make-com-job-board-with-gpt-5-mini-summaries---email-digest-9300


# Automatically Scrape Make.com Job Board with GPT-5-mini Summaries & Email Digest

---

### 1. Workflow Overview

This workflow automates the process of scraping job postings from the Make.com professional services forum, generating AI-powered summaries for each posting, and sending a weekly email digest of the latest job opportunities. It is designed for users who want to monitor new job openings efficiently with summarized content generated by GPT-5-mini, providing a clear and concise overview of each listing.

The workflow is logically divided into the following blocks:

- **1.1 Scheduled Trigger & Data Fetching:** Initiates the workflow weekly and fetches the main job board HTML.
- **1.2 Data Extraction & Filtering:** Extracts job posting links and metadata, formats them, and filters for recent posts (last 7 days).
- **1.3 Individual Job Processing & AI Summarization:** Retrieves individual job pages, extracts detailed HTML, and uses GPT-5-mini to generate structured summaries.
- **1.4 Data Aggregation & Email Digest Preparation:** Combines AI summaries with job metadata, cleans the data, aggregates all jobs, and formats a grouped HTML email.
- **1.5 Email Delivery:** Sends the formatted job digest email to the configured recipient.

---

### 2. Block-by-Block Analysis

#### 1.1 Scheduled Trigger & Data Fetching

- **Overview:** This block triggers the workflow every Monday at 9 AM and fetches the main job board page from Make.com to initiate data extraction.
- **Nodes Involved:**  
  - Run Weekly on Monday Morning  
  - Fetch Main Job Board

- **Node Details:**

  - **Run Weekly on Monday Morning**
    - Type: Schedule Trigger  
    - Role: Starts the workflow automatically every Monday at 09:00 local time using a cron expression (`0 9 * * 1`).  
    - Input: None (trigger)  
    - Output: Initiates the HTTP request to fetch job board page  
    - Edge Cases: Workflow won't run if n8n instance is down at trigger time.  
    - Version: 1.2  

  - **Fetch Main Job Board**
    - Type: HTTP Request  
    - Role: Retrieves the HTML content of the Make.com professional services forum jobs page (`https://community.make.com/tag/professional-service`).  
    - Configuration: Simple GET request with default options.  
    - Input: Trigger from schedule node  
    - Output: Raw HTML content for downstream HTML parsing  
    - Edge Cases: Network failure, 404 or 5xx HTTP errors, page structure changes affecting downstream parsing.  
    - Version: 4.2  

---

#### 1.2 Data Extraction & Filtering

- **Overview:** Parses the main job board HTML to extract job titles, links, and posting dates; formats this data into structured items; and filters out jobs older than 7 days.
- **Nodes Involved:**  
  - Extract Job Post Links  
  - Format Job List Items  
  - Filter New/Valid Jobs

- **Node Details:**

  - **Extract Job Post Links**
    - Type: HTML Extract  
    - Role: Parses the fetched HTML to extract arrays of job titles, job links (href attributes), and posting dates using CSS selectors.  
    - Configuration:  
      - Extracts `.topic-list-item .main-link .link-top-line a` for titles and links  
      - Extracts `.topic-list-item td:last-child` for dates  
      - Returns arrays for each field  
    - Input: HTML from Fetch Main Job Board  
    - Output: JSON object with arrays of jobTitle, jobLink, date  
    - Edge Cases: Changes in page layout or CSS selectors may break extraction. Empty or malformed HTML input.  
    - Version: 1.2  

  - **Format Job List Items**
    - Type: Code (JavaScript)  
    - Role: Transforms parallel arrays of titles, links, and dates into an array of structured job objects with consistent keys and adds a "source" field set to `"make-forum"`.  
    - Configuration: Uses JavaScript to map arrays to objects with properties: `jobTitle`, `jobLink`, `date`, `source`.  
    - Input: Extracted arrays from previous node  
    - Output: Array of job objects, each as a separate item for downstream iteration  
    - Edge Cases: Mismatched array lengths could cause indexing errors (assumes arrays are same length).  
    - Version: 2  

  - **Filter New/Valid Jobs**
    - Type: Filter  
    - Role: Filters job items to only include those posted within the last 7 days based on the `date` field.  
    - Configuration:  
      - Condition: `date` field is after current date minus 7 days (using expression)  
      - Case sensitive and strict validation enabled  
    - Input: Formatted job items  
    - Output:  
      - True branch: jobs newer than 7 days for further processing  
      - False branch: older jobs discarded  
    - Edge Cases: Incorrect date formats could cause filtering to fail. Timezone discrepancies may affect filtering accuracy.  
    - Version: 2.2  

---

#### 1.3 Individual Job Processing & AI Summarization

- **Overview:** For each recent job, fetches the individual job page, extracts the HTML description, and uses GPT-5-mini with a structured output parser to generate a high-level summary of the clientâ€™s needs.
- **Nodes Involved:**  
  - Get Individual Job Page  
  - Get Page HTML for LLM  
  - OpenRouter Chat Model  
  - Structured Output Parser  
  - Extract Job Details with AI

- **Node Details:**

  - **Get Individual Job Page**
    - Type: HTTP Request  
    - Role: Fetches the full HTML content of each individual job posting by using the extracted jobLink URL.  
    - Configuration: URL set dynamically via expression `={{ $json.jobLink }}`  
    - Input: Filtered recent jobs  
    - Output: Raw job page HTML  
    - Edge Cases: 404 for removed jobs, network errors, rate limiting, or redirects could affect fetching.  
    - Version: 4.2  

  - **Get Page HTML for LLM**
    - Type: HTML Extract  
    - Role: Extracts the meta description content (`og:description`) from the job page HTML to provide concise text input for AI summarization.  
    - Configuration: Extracts `content` attribute from `meta[property="og:description"]`  
    - Input: Job page HTML from previous node  
    - Output: JSON with `jobDescription` string  
    - Edge Cases: Missing or malformed meta tags could result in empty or irrelevant input for AI.  
    - Version: 1.2  

  - **OpenRouter Chat Model**
    - Type: AI Language Model (OpenRouter GPT-5-mini)  
    - Role: Interfaces with OpenRouterâ€™s GPT-5-mini model to process job description text and generate a summary.  
    - Configuration: Model set to `openai/gpt-5-mini` with no additional options. Uses OpenRouter API credentials.  
    - Input: Job description text from HTML extraction  
    - Output: Raw AI response (unstructured)  
    - Edge Cases: API authentication errors, rate limits, timeouts, or malformed prompts may cause failures.  
    - Version: 1  

  - **Structured Output Parser**
    - Type: LangChain Structured Output Parser  
    - Role: Parses the AI modelâ€™s raw response into structured JSON using a defined schema example focusing on the `summary` field.  
    - Configuration: JSON schema example specifying a single `summary` string property.  
    - Input: Raw AI outputs  
    - Output: Parsed JSON with clean, structured summary  
    - Edge Cases: AI output not matching schema causing parsing errors or exceptions.  
    - Version: 1.2  

  - **Extract Job Details with AI**
    - Type: LangChain Chain LLM  
    - Role: Orchestrates the AI prompt with instructions and handles output parsing using the Structured Output Parser.  
    - Configuration:  
      - Prompt instructs to extract a high-level summary of what the client wants to build from the job description HTML.  
      - Output parser enabled to ensure JSON output.  
    - Input: Job description text from `Get Page HTML for LLM`  
    - Output: Parsed AI summary JSON  
    - Edge Cases: Prompt misinterpretation or unexpected AI output format.  
    - Version: 1.5  

---

#### 1.4 Data Aggregation & Email Digest Preparation

- **Overview:** Combines the AI-generated summaries with job metadata, cleans the data for email formatting, aggregates all jobs into a single dataset, and prepares the HTML email body grouped by source.
- **Nodes Involved:**  
  - Combine AI Data & URL  
  - Clean AI Response  
  - Aggregate All Jobs  
  - (Sticky Notes related to AI extraction and email formatting)

- **Node Details:**

  - **Combine AI Data & URL**
    - Type: Merge  
    - Role: Combines three input streams by position: job metadata, individual job HTML extraction, and AI summaries into single items for each job.  
    - Configuration: Mode set to "combine" by position index. Three inputs connected:  
      1. From `Filter New/Valid Jobs` (job metadata)  
      2. From `Get Page HTML for LLM` (job description HTML)  
      3. From `Extract Job Details with AI` (summary JSON)  
    - Input: Three streams as above  
    - Output: Single merged job item with all relevant data fields  
    - Edge Cases: Mismatched input counts could cause data misalignment.  
    - Version: 3  

  - **Clean AI Response**
    - Type: Code (JavaScript)  
    - Role: Cleans combined data by extracting only the summary field from AI output and removing extraneous output details.  
    - Configuration: Maps all input items, sets `summary` from `output.summary`, deletes `output` property.  
    - Input: Combined job data with AI output  
    - Output: Cleaned JSON with job metadata and summary only  
    - Edge Cases: Missing or malformed AI output properties may cause undefined fields.  
    - Version: 2  

  - **Aggregate All Jobs**
    - Type: Code (JavaScript)  
    - Role: Aggregates all cleaned job items into a single object with a `data` property containing an array of all jobs for email preparation.  
    - Configuration: Collects all input items into an array and returns as `{ data: items }`  
    - Input: Cleaned job summaries  
    - Output: Single aggregated data object holding all jobs  
    - Edge Cases: Large data volume could impact performance.  
    - Version: 2  

---

#### 1.5 Email Delivery

- **Overview:** Formats the aggregated job data into a styled HTML email, grouping jobs by source (Make Forum), and sends the digest email to the configured recipient.
- **Nodes Involved:**  
  - Send Weekly Job Digest  
  - Sticky Note3 (email formatting instructions)

- **Node Details:**

  - **Send Weekly Job Digest**
    - Type: Email Send  
    - Role: Sends an HTML email containing the weekly job digest with jobs sorted and grouped by their source.  
    - Configuration:  
      - HTML body dynamically generated using JavaScript within the node parameters.  
      - Groups jobs by source and sorts by posting date descending.  
      - Email subject: "Job Opportunities"  
      - To and From emails set to `test@example.com` (should be updated in deployment)  
      - Uses SMTP credentials configured in n8n.  
    - Input: Aggregated job data object  
    - Output: Email sent confirmation  
    - Edge Cases: SMTP authentication failures, email address misconfiguration, large email content size.  
    - Version: 2.1  

---

### 3. Summary Table

| Node Name                  | Node Type                              | Functional Role                        | Input Node(s)                         | Output Node(s)                   | Sticky Note                                                                                                      |
|----------------------------|--------------------------------------|-------------------------------------|-------------------------------------|---------------------------------|-----------------------------------------------------------------------------------------------------------------|
| Run Weekly on Monday Morning| Schedule Trigger                     | Weekly trigger to start workflow     | None                                | Fetch Main Job Board             |                                                                                                                 |
| Fetch Main Job Board        | HTTP Request                        | Fetch main Make.com job board HTML  | Run Weekly on Monday Morning        | Extract Job Post Links           |                                                                                                                 |
| Extract Job Post Links      | HTML Extract                        | Extract job titles, links, and dates| Fetch Main Job Board                 | Format Job List Items            |                                                                                                                 |
| Format Job List Items       | Code                               | Format arrays into structured job items| Extract Job Post Links            | Filter New/Valid Jobs            |                                                                                                                 |
| Filter New/Valid Jobs       | Filter                             | Filter jobs posted within last 7 days| Format Job List Items             | Get Individual Job Page, Combine AI Data & URL (input 2)| ## â±ï¸ DATE FILTERING Only processes jobs posted within the last 7 days. Adjust the filter condition to change this timeframe. |
| Get Individual Job Page     | HTTP Request                      | Fetch individual job page HTML       | Filter New/Valid Jobs               | Get Page HTML for LLM, Extract Job Details with AI |                                                                                                                 |
| Get Page HTML for LLM       | HTML Extract                      | Extract job description meta content | Get Individual Job Page             | Combine AI Data & URL (input 1)  |                                                                                                                 |
| OpenRouter Chat Model       | AI Language Model (OpenRouter GPT) | Generate AI summary of job description| Extract Job Details with AI (input) | Extract Job Details with AI (output) | ## ðŸ¤– AI EXTRACTION Uses GPT-5-mini to read the job posting HTML and extract a clear summary of what the client wants to build. |
| Structured Output Parser    | LangChain Output Parser            | Parse AI raw response into JSON     | OpenRouter Chat Model               | Extract Job Details with AI      |                                                                                                                 |
| Extract Job Details with AI | LangChain Chain LLM                | Orchestrate AI prompt & parsing     | Get Individual Job Page, OpenRouter Chat Model, Structured Output Parser | Combine AI Data & URL (input 3) |                                                                                                                 |
| Combine AI Data & URL       | Merge                             | Combine job metadata, HTML, and AI summaries | Filter New/Valid Jobs (input 2), Get Page HTML for LLM, Extract Job Details with AI | Clean AI Response               |                                                                                                                 |
| Clean AI Response           | Code                              | Clean merged data, keep only summary| Combine AI Data & URL               | Aggregate All Jobs               |                                                                                                                 |
| Aggregate All Jobs          | Code                              | Aggregate all jobs into one object  | Clean AI Response                  | Send Weekly Job Digest           |                                                                                                                 |
| Send Weekly Job Digest      | Email Send                        | Format and send weekly job digest   | Aggregate All Jobs                  | None                            | ## ðŸ“§ EMAIL FORMATTING Creates a beautiful HTML email with jobs organized by source. Update the fromEmail and toEmail parameters to your addresses. |
| Sticky Note                 | Sticky Note                      | Workflow overview                   | None                               | None                           | ## ðŸ“‹ WORKFLOW OVERVIEW This automation scrapes Make.com's professional services forum for job postings, uses AI to summarize each opportunity, and emails you a digest of jobs from the last 7 days. |
| Sticky Note1                | Sticky Note                      | Date filtering explanation          | None                               | None                           | ## â±ï¸ DATE FILTERING Only processes jobs posted within the last 7 days. Adjust the filter condition to change this timeframe. |
| Sticky Note2                | Sticky Note                      | AI extraction explanation           | None                               | None                           | ## ðŸ¤– AI EXTRACTION Uses GPT-5-mini to read the job posting HTML and extract a clear summary of what the client wants to build. |
| Sticky Note3                | Sticky Note                      | Email formatting explanation        | None                               | None                           | ## ðŸ“§ EMAIL FORMATTING Creates a beautiful HTML email with jobs organized by source. Update the fromEmail and toEmail parameters to your addresses. |

---

### 4. Reproducing the Workflow from Scratch

1. **Create a Schedule Trigger Node**  
   - Node Name: `Run Weekly on Monday Morning`  
   - Type: Schedule Trigger  
   - Configure cron expression to `0 9 * * 1` (every Monday at 9:00 AM).

2. **Create HTTP Request Node**  
   - Node Name: `Fetch Main Job Board`  
   - Type: HTTP Request  
   - Set URL to `https://community.make.com/tag/professional-service`  
   - Connect output from `Run Weekly on Monday Morning` to this node.

3. **Create HTML Extract Node**  
   - Node Name: `Extract Job Post Links`  
   - Type: HTML Extract  
   - Set operation to Extract HTML Content  
   - Add extraction values:  
     - `jobTitle`: CSS Selector `.topic-list-item .main-link .link-top-line a`, return as array  
     - `jobLink`: CSS Selector `.topic-list-item .main-link .link-top-line a`, attribute `href`, return as array  
     - `date`: CSS Selector `.topic-list-item td:last-child`, return as array  
   - Connect output from `Fetch Main Job Board`.

4. **Create Code Node**  
   - Node Name: `Format Job List Items`  
   - Type: Code (JavaScript)  
   - Paste the following code:
     ```javascript
     const titles = items[0].json["jobTitle"];
     const links = items[0].json["jobLink"];
     const dates = items[0].json["date"];

     const merged = titles.map((title, index) => ({
       jobTitle: title,
       jobLink: links[index],
       date: dates[index],
       source: "make-forum"
     }));

     return merged.map(item => ({ json: item }));
     ```
   - Connect output from `Extract Job Post Links`.

5. **Create Filter Node**  
   - Node Name: `Filter New/Valid Jobs`  
   - Type: Filter  
   - Add condition:  
     - Left value: `{{$json.date}}`  
     - Operator: DateTime "after"  
     - Right value: `{{$now.minus({days:7})}}`  
   - Connect output from `Format Job List Items`.

6. **Create HTTP Request Node**  
   - Node Name: `Get Individual Job Page`  
   - Type: HTTP Request  
   - URL set via expression: `{{$json.jobLink}}`  
   - Connect the **true** output from `Filter New/Valid Jobs`.

7. **Create HTML Extract Node**  
   - Node Name: `Get Page HTML for LLM`  
   - Type: HTML Extract  
   - Extract meta tag content: CSS Selector `meta[property="og:description"]`, attribute `content`  
   - Connect output from `Get Individual Job Page`.

8. **Create AI Language Model Node (OpenRouter GPT-5-mini)**  
   - Node Name: `OpenRouter Chat Model`  
   - Type: LangChain - OpenRouter Chat Model  
   - Model: `openai/gpt-5-mini`  
   - Connect output to a LangChain Chain LLM node (next step)  
   - Use appropriate OpenRouter API credentials.

9. **Create LangChain Structured Output Parser Node**  
   - Node Name: `Structured Output Parser`  
   - Type: LangChain Output Parser (Structured)  
   - Configure JSON schema example:
     ```json
     {
       "summary": "What the client is looking to build"
     }
     ```
   - Connect parser output to LangChain Chain LLM node.

10. **Create LangChain Chain LLM Node**  
    - Node Name: `Extract Job Details with AI`  
    - Type: LangChain Chain LLM  
    - Set prompt to:
      ```
      <prompt>
          <purpose>
              Based on this HTML your task is to provide a summary of what the client is looking to build with the automation software make.com
          </purpose>
          <instructions>
              <instruction>Output in json format</instruction>
              <instruction>Give a high level summary of what the client wants to build</instruction>
              <instruction>Make sure to only distill the relevant text from all the HTML input</instruction>
          </instructions>
      </prompt>
      ```
    - Enable output parser and link to Structured Output Parser node.  
    - Input text mapped from extracted job description (`jobDescription` field).  
    - Connect `OpenRouter Chat Model` as AI model input.  
    - Connect outputs from `Get Individual Job Page` (for raw HTML), `OpenRouter Chat Model`, and `Structured Output Parser` into this node.

11. **Create Merge Node**  
    - Node Name: `Combine AI Data & URL`  
    - Type: Merge  
    - Mode: Combine  
    - Combine by position  
    - Inputs:  
      - Input 1: True output from `Filter New/Valid Jobs` (job metadata)  
      - Input 2: Output from `Get Page HTML for LLM`  
      - Input 3: Output from `Extract Job Details with AI`  
    - Connect accordingly.

12. **Create Code Node**  
    - Node Name: `Clean AI Response`  
    - Type: Code (JavaScript)  
    - Code:
      ```javascript
      return $input.all().map(item => ({
        ...item.json,
        summary: item.json.output.summary,
        output: undefined
      }));
      ```
    - Connect output from `Combine AI Data & URL`.

13. **Create Code Node**  
    - Node Name: `Aggregate All Jobs`  
    - Type: Code (JavaScript)  
    - Code:
      ```javascript
      const items = $input.all().map(item => item.json);
      return { data: items };
      ```
    - Connect output from `Clean AI Response`.

14. **Create Email Send Node**  
    - Node Name: `Send Weekly Job Digest`  
    - Type: Email Send  
    - Configure SMTP credentials  
    - Set To Email and From Email to desired addresses  
    - Subject: "Job Opportunities"  
    - HTML Body: Use the following JavaScript expression to generate grouped and formatted HTML email content:
      ```javascript
      return (() => {
        const grouped = $json.data.sort((a,b) => new Date(b.date.replace(/\s/, 'T')) - new Date(a.date.replace(/\s/, 'T'))).reduce((acc, job) => {
          const source = job.source === 'n8n-forum' ? 'n8n-forum' : 
                        job.source === 'make-forum' ? 'make-forum' : 
                        'reddit';
          if (!acc[source]) acc[source] = [];
          acc[source].push(job);
          return acc;
        }, {});
        
        return Object.entries(grouped).reduce((html, [source, jobs]) => 
          html + '<div class="section"><h2>' + 
          (source === 'n8n-forum' ? 'n8n Forum Jobs' : 
           source === 'make-forum' ? 'Make Forum Jobs' : 
           'Reddit Jobs') + '</h2>' +
          jobs.map(job => 
            '<div class="job-item"><h3><a href="' + job.jobLink + '">' + 
            job.jobTitle + '</a></h3><div class="date">Posted: ' + 
            job.date + '</div><div class="source">Source: ' + 
            (job.source === 'n8n-forum' ? 'n8n Forum' : 
             job.source === 'make-forum' ? 'Make Forum' : 
             'Reddit - ' + job.origin) + '</div><p class="summary">' + 
            job.summary + '</p></div>'
          ).join('') + '</div>',
          '<!DOCTYPE html><html><head><style>body{font-family:Arial,sans-serif;line-height:1.6;color:#333;max-width:800px;margin:0 auto;padding:20px}.section{margin-bottom:30px}.job-item{border:1px solid #ddd;margin-bottom:20px;padding:15px;border-radius:5px}h2{color:#2c5282;border-bottom:2px solid #2c5282;padding-bottom:10px;margin-top:30px}h3{color:#2c5282;margin:0 0 10px}a{color:#2b6cb0;text-decoration:none}a:hover{text-decoration:underline}.date,.source{color:#666;font-size:0.9em;margin-bottom:8px}.summary{background:#f8f9fa;padding:10px;border-left:4px solid #4299e1;margin:10px 0}</style></head><body><h1>Latest Job Opportunities</h1><p>Generated on: ' + new Date().toLocaleString() + '</p>'
        ) + '</body></html>';
      })();
      ```
    - Connect output from `Aggregate All Jobs`.

---

### 5. General Notes & Resources

| Note Content                                                                                                    | Context or Link                                                                                             |
|----------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| The workflow uses GPT-5-mini via OpenRouter API to summarize job postings efficiently.                          | AI Extraction block                                                                                         |
| Adjust the date filter in `Filter New/Valid Jobs` node to change the timeframe of job postings included.       | Date filtering logic                                                                                        |
| Update the SMTP credentials and email addresses in `Send Weekly Job Digest` node to route emails correctly.    | Email delivery configuration                                                                                |
| The email digest groups jobs by source (`make-forum`) with a clean HTML format styled using embedded CSS.      | Email formatting node                                                                                        |
| Workflow designed for Make.com professional services forum but can be adapted to similar job board structures. | Potential extension or customization                                                                        |

---

This document fully describes the structure, logic, and configuration of the "Automatically Scrape Make.com Job Board with GPT-5-mini Summaries & Email Digest" workflow, enabling reproduction, modification, and troubleshooting for advanced users and automation agents.

---