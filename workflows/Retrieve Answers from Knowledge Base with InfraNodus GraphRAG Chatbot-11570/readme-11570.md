Retrieve Answers from Knowledge Base with InfraNodus GraphRAG Chatbot

https://n8nworkflows.xyz/workflows/retrieve-answers-from-knowledge-base-with-infranodus-graphrag-chatbot-11570


# Retrieve Answers from Knowledge Base with InfraNodus GraphRAG Chatbot

### 1. Workflow Overview

This workflow implements a basic AI chatbot that retrieves answers from a knowledge base using InfraNodus GraphRAG technology. It is designed for support and productivity scenarios where users ask questions, and the system returns contextually enriched responses by querying a knowledge graph. The workflow is structured into three main logical blocks:

- **1.1 Chat Input Reception**: Captures user chat input via an n8n LangChain chat trigger node (or optionally a webhook for integration).
- **1.2 Knowledge Base Query Using InfraNodus GraphRAG**: Sends the user query to the InfraNodus GraphRAG node which processes the request against a specified knowledge graph.
- **1.3 Response Delivery**: Returns the generated answer back to the user either via the chat interface or the webhook response.

This setup avoids complexity such as vector stores, instead leveraging a domain-specific graph query approach for expert knowledge retrieval.

---

### 2. Block-by-Block Analysis

#### 1.1 Chat Input Reception

**Overview:**  
This block handles user input reception. It starts the workflow when a chat message is received using n8n’s LangChain chat trigger node. The node is publicly accessible and prompts the user with an initial greeting message.

**Nodes Involved:**  
- When chat message received  
- (Disabled) Webhook

**Node Details:**

- **When chat message received**  
  - Type: `@n8n/n8n-nodes-langchain.chatTrigger`  
  - Role: Entry point for chat input  
  - Configuration:  
    - Publicly available webhook  
    - Response mode set to return nodes (responseNodes)  
    - Initial system prompt: "What would you like to know?"  
  - Inputs: None (trigger)  
  - Outputs: User chat message to next node  
  - Version: 1.3  
  - Edge cases:  
    - Network or webhook accessibility issues  
    - User abandonment or no input  
  - Notes: Designed for testing with n8n’s built-in chat; can be replaced with webhook node for embedding.

- **Webhook (Disabled)**  
  - Type: `n8n-nodes-base.webhook`  
  - Role: Alternative input receiving method, currently disabled  
  - Parameters: Path configured but node inactive  
  - Used for integrating external input sources or embedding the chatbot externally.  
  - Edge cases: Authentication, webhook exposure security.

#### 1.2 Knowledge Base Query Using InfraNodus GraphRAG

**Overview:**  
This block queries the knowledge base using the InfraNodus GraphRAG node, which takes the user’s chat input and performs a graph-based retrieval to generate an expert answer.

**Nodes Involved:**  
- Get a response from knowledge base

**Node Details:**

- **Get a response from knowledge base**  
  - Type: `n8n-nodes-infranodus.infranodus` (InfraNodus integration node)  
  - Role: Query InfraNodus knowledge graph using GraphRAG technology  
  - Configuration:  
    - Graph name: "infranodus_support" (target knowledge base graph)  
    - Prompt dynamically set from user input: `{{$json.chatInput}}`  
    - Request options default (empty)  
  - Credentials: InfraNodus API key configured under "InfraNodus API / user expert"  
  - Input: User chat input from chat trigger node  
  - Outputs: JSON response containing array `aiAdvice` with text answer  
  - Version: 1  
  - Edge cases:  
    - API authentication failures  
    - Network timeout or rate limiting from InfraNodus API  
    - Empty or malformed user input causing no meaningful response  
  - Notes: No vector store or additional AI models needed; relies entirely on InfraNodus graph and API.

#### 1.3 Response Delivery

**Overview:**  
This block sends the answer generated by the InfraNodus node back to the user via chat or webhook response.

**Nodes Involved:**  
- Respond to Chat  
- (Disabled) Respond to Webhook  

**Node Details:**

- **Respond to Chat**  
  - Type: `@n8n/n8n-nodes-langchain.chat`  
  - Role: Sends AI-generated message back to user chat interface  
  - Configuration:  
    - Message set using expression: `{{$json.aiAdvice[0].text}}` (first answer text)  
    - WaitUserReply: false (one-way reply)  
  - Input: InfraNodus node output  
  - Output: None (final response)  
  - Version: 1  
  - Edge cases:  
    - Missing or empty `aiAdvice` array causing undefined message  
    - Delays or errors in chat response delivery

- **Respond to Webhook (Disabled)**  
  - Type: `n8n-nodes-base.respondToWebhook`  
  - Role: Alternative response method for webhook integration, currently disabled  
  - Configuration: Response body set to the same AI advice text  
  - Used when integrating via webhook instead of chat trigger.

---

### 3. Summary Table

| Node Name                   | Node Type                             | Functional Role                     | Input Node(s)               | Output Node(s)                      | Sticky Note                                                                                   |
|-----------------------------|-------------------------------------|-----------------------------------|-----------------------------|------------------------------------|----------------------------------------------------------------------------------------------|
| When chat message received  | @n8n/n8n-nodes-langchain.chatTrigger | Receive user chat input           | None                        | Get a response from knowledge base | ## 1. AI Chat Trigger<br>Use the n8n built-in chat for testing and then replace this node with a Webhook node and expose to your users via the embeddable [n8n Chat Widget](https://n8n-chat-widget.com). |
| Webhook (disabled)           | n8n-nodes-base.webhook              | Alternative input reception       | None                        | Get a response from knowledge base |                                                                                              |
| Get a response from knowledge base | n8n-nodes-infranodus.infranodus     | Query InfraNodus GraphRAG knowledge base | When chat message received, Webhook | Respond to Chat, Respond to Webhook | ## 2. Query the Knowledge Base<br>Use the [InfraNodus GraphRAG node](https://n8n.io/integrations/infranodus-graph-rag/) to generate an answer to your query. No need to add vector store or additional model connectors.<br>To set up, you need to provide:<br>- Your [InfraNodus API key](https://infranodus.com/api-access)<br>- The name of the graph you'll query. Learn how to [create the graph in InfraNodus](.\nRead more about [GraphRAG](https://infranodus.com/docs/graph-rag-knowledge-graph) |
| Respond to Chat              | @n8n/n8n-nodes-langchain.chat       | Deliver answer to chat user       | Get a response from knowledge base | None                               | ## 3. Show response to the user<br>The response obtained using InfraNodus GraphRAG is then shown to the user. |
| Respond to Webhook (disabled) | n8n-nodes-base.respondToWebhook     | Deliver answer via webhook        | Get a response from knowledge base | None                               |                                                                                              |
| Sticky Note                  | n8n-nodes-base.stickyNote           | Documentation note                | None                        | None                               | ## 1. AI Chat Trigger<br>Use the n8n built-in chat for testing and then replace this node with a Webhook node and expose to your users via the embeddable [n8n Chat Widget](https://n8n-chat-widget.com). |
| Sticky Note1                 | n8n-nodes-base.stickyNote           | Documentation note                | None                        | None                               | ## 2. Query the Knowledge Base<br>Use the [InfraNodus GraphRAG node](https://n8n.io/integrations/infranodus-graph-rag/) to generate an answer to your query. No need to add vector store or additional model connectors.<br>To set up, you need to provide:<br>- Your [InfraNodus API key](https://infranodus.com/api-access)<br>- The name of the graph you'll query. Learn how to [create the graph in InfraNodus](.\nRead more about [GraphRAG](https://infranodus.com/docs/graph-rag-knowledge-graph) |
| Sticky Note2                 | n8n-nodes-base.stickyNote           | Documentation note                | None                        | None                               | ## 3. Show response to the user<br>The response obtained using InfraNodus GraphRAG is then shown to the user. |
| Sticky Note3                 | n8n-nodes-base.stickyNote           | Documentation note                | None                        | None                               | ## Basic AI Chatbot Tutorial<br>- No vector store needed<br>- Uses GraphRAG and custom ontology for responses<br>### Learn how to set up a simple AI chatbot without vector store and complex AI agent setups in this [support article](https://support.noduslabs.com/hc/en-us/articles/24079266183196-Building-Expert-Ontology-for-InfraNodus-GraphRAG-n8n-Expert-Node) and this video tutorial: <br>[![Video tutorial](https://img.youtube.com/vi/qP4KTLBzoWQ/sddefault.jpg)](https://www.youtube.com/watch?v=qP4KTLBzoWQ) |

---

### 4. Reproducing the Workflow from Scratch

1. **Create the Chat Trigger Node**  
   - Add node: `@n8n/n8n-nodes-langchain.chatTrigger`  
   - Set: Public access enabled  
   - Configure initialMessages: "What would you like to know?"  
   - Set responseMode: `responseNodes`  
   - Position at top left for clarity.

2. **Add InfraNodus Node**  
   - Add node: `n8n-nodes-infranodus.infranodus`  
   - Set graph name parameter to `"infranodus_support"` (or your knowledge graph name)  
   - Set prompt parameter expression to `{{$json.chatInput}}` to use chat input dynamically  
   - Leave requestOptions empty unless specific API options needed  
   - Configure credentials: Create and assign an InfraNodus API credential (requires API key from https://infranodus.com/api-access)  
   - Connect chat trigger node output to this node input.

3. **Add Chat Response Node**  
   - Add node: `@n8n/n8n-nodes-langchain.chat`  
   - Set message expression to `{{$json.aiAdvice[0].text}}` (extract first returned answer text)  
   - Set waitUserReply to `false` to send one-way message  
   - Connect InfraNodus node output to this node input.

4. **(Optional) Add Webhook and Respond to Webhook Nodes**  
   - Add `Webhook` node with desired path, enable if replacing chat trigger for external integration  
   - Add `Respond to Webhook` node, configure response body as `{{$json.aiAdvice[0].text}}`  
   - Connect webhook output to InfraNodus node, then InfraNodus output to respond node.

5. **Link Nodes**  
   - Connect:  
     - Chat Trigger → InfraNodus Node  
     - InfraNodus Node → Respond to Chat (and optionally Respond to Webhook)  

6. **Test the Workflow**  
   - Activate workflow  
   - Use the chat interface or webhook URL to send queries  
   - Validate responses are returned accurately from InfraNodus graph

7. **Add Sticky Notes for Documentation**  
   - Add and position sticky notes to describe each logical block and important configuration tips (optional but recommended).

---

### 5. General Notes & Resources

| Note Content                                                                                                                                                                                                                                                                                                   | Context or Link                                                                                                                      |
|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|
| Use the embeddable [n8n Chat Widget](https://n8n-chat-widget.com) to expose the chatbot externally with the webhook node.                                                                                                                                                                                     | Integration and deployment                                                                                                         |
| Learn how to build expert ontologies for InfraNodus GraphRAG in this detailed [support article](https://support.noduslabs.com/hc/en-us/articles/24079266183196-Building-Expert-Ontology-for-InfraNodus-GraphRAG-n8n-Expert-Node) and watch this [video tutorial](https://www.youtube.com/watch?v=qP4KTLBzoWQ). | Expert knowledge base creation and GraphRAG setup                                                                                   |
| InfraNodus GraphRAG requires no vector store or additional AI model connectors, simplifying AI chatbot development focused on graph-based knowledge retrieval.                                                                                                                                              | Architectural note                                                                                                                 |

---

**Disclaimer:** The text provided is exclusively derived from an n8n automated workflow, fully compliant with content policies. It contains no illegal, offensive, or protected content. All data handled is legal and publicly available.