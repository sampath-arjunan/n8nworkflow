AI-Powered RAG Document Processing & Chatbot with Google Drive, Supabase, OpenAI

https://n8nworkflows.xyz/workflows/ai-powered-rag-document-processing---chatbot-with-google-drive--supabase--openai-4551


# AI-Powered RAG Document Processing & Chatbot with Google Drive, Supabase, OpenAI

### 1. Workflow Overview

This workflow automates the ingestion, processing, indexing, and interactive querying of documents uploaded to a specific Google Drive folder by leveraging AI technologies and vector databases. It is designed for use cases where organizations want to create an AI-powered Retrieval-Augmented Generation (RAG) system that transforms raw documents (PDFs, CSVs, Google Docs) into searchable knowledge bases and enables conversational interactions with those documents.

The logical blocks are:

- **1.1 Data Ingestion & Extraction:** Monitors Google Drive for new files, downloads them, and extracts text content depending on file type (PDF or CSV).
- **1.2 Document Preparation & Metadata Generation:** Formats extracted text, uses AI to generate metadata (title, description), and splits documents into manageable chunks.
- **1.3 Chunk Context Enhancement & Summarization:** Enhances the chunks‚Äô context via an AI model and summarizes combined chunks for better indexing.
- **1.4 Embedding & Vector Store Insertion:** Converts text chunks into vector embeddings using OpenAI and inserts them into a Supabase vector store with rich metadata.
- **1.5 AI Chat Interface:** Listens for user chat input, performs semantic search on the vector store, maintains conversation context, and generates AI-powered answers referencing document data.

---

### 2. Block-by-Block Analysis

#### 2.1 Data Ingestion & Extraction

- **Overview:**  
  This block watches a specific Google Drive folder for new file uploads, downloads files, and extracts raw text content from PDFs or CSVs, preparing data for AI processing.

- **Nodes Involved:**  
  - Google Drive Trigger File Created  
  - Loop Over Items  
  - Set File ID  
  - Download File  
  - Switch (File Type)  
  - Extract from PDF  
  - Extract from CSV  
  - Document Data  

- **Node Details:**

  - **Google Drive Trigger File Created**  
    - *Type:* Trigger node, Google Drive Trigger  
    - *Role:* Watches a specified Google Drive folder (configured by URL) for new file creation, triggering every minute.  
    - *Configuration:* Watches folder ID `1B-Wl-ktVFbTmX685DB978jNvs9Ihnxiv`.  
    - *Inputs:* None (trigger node)  
    - *Outputs:* Array of files created  
    - *Potential issues:* Authentication errors, API quota limits, folder permission issues.

  - **Loop Over Items**  
    - *Type:* Split in Batches  
    - *Role:* Processes each uploaded file one by one to avoid bulk processing errors.  
    - *Configuration:* Default batch size (processes items individually).  
    - *Inputs:* Files from Google Drive Trigger  
    - *Outputs:* Single file per iteration  
    - *Potential issues:* Large batch sizes may cause timeouts.

  - **Set File ID**  
    - *Type:* Set  
    - *Role:* Extracts and stores the Google Drive file ID from the current item for downstream referencing.  
    - *Key Expression:* `file_id = {{$json.id}}`  
    - *Inputs:* Single file item  
    - *Outputs:* File ID in JSON field `file_id`  
    - *Potential issues:* Missing file ID field if Google Drive API changes.

  - **Download File**  
    - *Type:* Google Drive node  
    - *Role:* Downloads the file corresponding to `file_id`; Google Docs are converted to PDF format.  
    - *Configuration:* File ID set dynamically from `Set File ID`; conversion enabled for Google Docs to PDF.  
    - *Inputs:* `file_id` from previous node  
    - *Outputs:* Binary file data with MIME type information  
    - *Potential issues:* Download failures, file access permissions, conversion errors.

  - **Switch (File Type)**  
    - *Type:* Switch  
    - *Role:* Routes the workflow based on the MIME type of the downloaded file.  
    - *Configuration:* Routes into two outputs:  
      - `application/pdf` ‚Üí PDF extraction  
      - `text/csv` ‚Üí CSV extraction  
    - *Inputs:* Binary data with MIME type from `Download File`  
    - *Outputs:* Routed to PDF or CSV extraction nodes  
    - *Potential issues:* Unsupported MIME types, misidentified file types.

  - **Extract from PDF**  
    - *Type:* Extract from File  
    - *Role:* Extracts raw text from the PDF binary data.  
    - *Configuration:* Operation set to `pdf`.  
    - *Inputs:* PDF binary data from Switch node  
    - *Outputs:* Extracted text string  
    - *Potential issues:* Complex PDFs with images only may yield no text; extraction failures.

  - **Extract from CSV**  
    - *Type:* Extract from File  
    - *Role:* Extracts and formats CSV content into a readable string representation.  
    - *Inputs:* CSV binary data from Switch node  
    - *Outputs:* Extracted textual CSV data  
    - *Potential issues:* Malformed CSV files, encoding issues.

  - **Document Data**  
    - *Type:* Set  
    - *Role:* Wraps extracted text into a JSON object under the `data` field for downstream AI processing.  
    - *Key Expression:* JSON stringified wrapped text: `{"data": <extracted text>}`  
    - *Inputs:* Extracted text from either PDF or CSV extraction  
    - *Outputs:* JSON with document text in `data` field  
    - *Potential issues:* Large text causing JSON parsing issues.

---

#### 2.2 Document Preparation & Metadata Generation

- **Overview:**  
  This block generates human-readable metadata (title, description) for documents using AI, splits documents into manageable chunks, and prepares them for vectorization.

- **Nodes Involved:**  
  - Create Metadata Title & Description  
  - Structured Output Parser  
  - Split into chunks  
  - Split Out  
  - Limit  

- **Node Details:**

  - **Create Metadata Title & Description**  
    - *Type:* LangChain Chain LLM  
    - *Role:* Uses Google Gemini AI to generate metadata title and description from the document text.  
    - *Prompt:* Requests creation of title and description based on document content.  
    - *Inputs:* Document text JSON from `Document Data`  
    - *Outputs:* AI-generated metadata JSON with `title` and `description` fields  
    - *Potential issues:* AI might generate irrelevant or generic metadata if input text is insufficient.

  - **Structured Output Parser**  
    - *Type:* LangChain Output Parser  
    - *Role:* Parses the AI-generated metadata into structured JSON format.  
    - *JSON Schema Example:* Requires `title` and `description` fields.  
    - *Inputs:* AI text output from `Create Metadata Title & Description`  
    - *Outputs:* Validated structured JSON metadata  
    - *Potential issues:* Parsing errors if AI output deviates from schema.

  - **Split into chunks (Code node)**  
    - *Type:* Code (JavaScript)  
    - *Role:* Splits the entire document text into chunks of approx. 1000 characters with 200 characters overlap for context preservation.  
    - *Logic:* Attempts splitting preferentially at paragraph, then sentence, then word boundaries; falls back to hard split.  
    - *Inputs:* Document text from `Document Data`  
    - *Outputs:* Array of text chunks in `chunks` field  
    - *Potential issues:* Very short documents may produce few chunks; overlapping text might cause redundancy.

  - **Split Out**  
    - *Type:* Split Out  
    - *Role:* Converts the array of chunks into individual workflow items for parallel processing.  
    - *Field to split out:* `chunks`  
    - *Outputs:* Individual chunk items  
    - *Potential issues:* Large number of chunks can cause workflow overload.

  - **Limit**  
    - *Type:* Limit  
    - *Role:* Caps the number of chunks processed to 20 to control API usage and processing time.  
    - *Configuration:* Max items = 20  
    - *Inputs:* Individual chunk items  
    - *Outputs:* Max 20 chunk items  
    - *Potential issues:* Document chunks beyond the 20th are ignored, possibly losing data.

---

#### 2.3 Chunk Context Enhancement & Summarization

- **Overview:**  
  Enhances each text chunk with improved context and clarity using AI, then summarizes combined chunks for better indexing.

- **Nodes Involved:**  
  - Process Context  
  - Summarize  

- **Node Details:**

  - **Process Context**  
    - *Type:* LangChain Chain LLM (Google Gemini Chat Model)  
    - *Role:* For each chunk, generates a succinct context to situate the chunk within the overall document. It also corrects incomplete numbers/entities and reconstructs partially cut sentences or tables.  
    - *Prompt:* Structured instructions to enhance chunk clarity without adding extraneous content.  
    - *Inputs:*  
      - Full document data (from `Document Data`)  
      - Single chunk text (current item)  
    - *Outputs:* Text combining succinct context and corrected chunk  
    - *Potential issues:* AI may fail to reconstruct incomplete data correctly; latency or quota limits on Gemini API.

  - **Summarize**  
    - *Type:* Summarize  
    - *Role:* Concatenates all enhanced chunks into a single text string separated by a custom delimiter `###SPLIT###` for reprocessing.  
    - *Configuration:* Concatenates field `text` with separator `###SPLIT###`.  
    - *Inputs:* Enhanced chunk texts from `Process Context`  
    - *Outputs:* Concatenated text string  
    - *Potential issues:* Excessively large concatenated text may exceed limits in downstream processing.

---

#### 2.4 Embedding & Vector Store Insertion

- **Overview:**  
  Converts enhanced text chunks into vector embeddings, attaches metadata, and inserts them into a Supabase vector store for semantic search.

- **Nodes Involved:**  
  - Character Text Splitter  
  - Default Data Loader  
  - Embeddings OpenAI  
  - Add Data to Supabase Vector Store  

- **Node Details:**

  - **Character Text Splitter**  
    - *Type:* LangChain Text Splitter (Character-based)  
    - *Role:* Splits the summarized text back into chunks using the `###SPLIT###` separator for embedding.  
    - *Configuration:* Separator set to `###SPLIT###`.  
    - *Inputs:* Concatenated summarized text from `Summarize`  
    - *Outputs:* Split chunks for embedding  
    - *Potential issues:* Improper delimiters cause incorrect splitting.

  - **Default Data Loader**  
    - *Type:* LangChain Document Default Data Loader  
    - *Role:* Wraps each chunk with metadata (file_id, title, description) for insertion into the vector store.  
    - *Metadata fields:* Dynamically assigned from earlier metadata nodes and file ID.  
    - *Inputs:* Split chunks from `Character Text Splitter`  
    - *Outputs:* Document objects with content and metadata  
    - *Potential issues:* Missing metadata causes incomplete records.

  - **Embeddings OpenAI**  
    - *Type:* LangChain Embeddings (OpenAI)  
    - *Role:* Converts each document chunk into a vector embedding compatible with Supabase vector search.  
    - *Credentials:* Uses OpenAI API key.  
    - *Inputs:* Document text chunks from `Default Data Loader`  
    - *Outputs:* Vector embeddings  
    - *Potential issues:* API rate limits, embedding size constraints.

  - **Add Data to Supabase Vector Store**  
    - *Type:* LangChain Vector Store (Supabase)  
    - *Role:* Inserts embeddings with accompanying metadata into the Supabase `documents` table for semantic retrieval.  
    - *Configuration:* Insert mode; target table `documents`  
    - *Credentials:* Supabase API key and project URL  
    - *Inputs:* Embeddings from OpenAI node  
    - *Outputs:* Confirmation of insertion  
    - *Potential issues:* Database connectivity issues, schema mismatches, quota limits.

---

#### 2.5 AI Chat Interface

- **Overview:**  
  Enables users to chat in natural language and receive AI-generated answers sourced from documents stored in Supabase. Maintains conversation context and uses vector search for retrieval.

- **Nodes Involved:**  
  - When chat message received  
  - AI Agent  
  - Simple Memory  
  - Supabase Vector Store  
  - Embeddings OpenAI1  
  - OpenAI Chat Model  

- **Node Details:**

  - **When chat message received**  
    - *Type:* LangChain Chat Trigger (Webhook)  
    - *Role:* Listens for incoming chat messages (user input) via webhook trigger.  
    - *Inputs:* User chat text (`chatInput`)  
    - *Outputs:* Chat input forwarded to AI agent  
    - *Potential issues:* Webhook availability, security/authentication.

  - **AI Agent**  
    - *Type:* LangChain Agent  
    - *Role:* Orchestrates the chat response process:  
      - Uses Supabase vector search to find relevant document chunks  
      - Uses conversation memory to maintain context  
      - Generates answers based on found data  
      - Returns ‚ÄúI couldn't find this in the databases‚Äù if no relevant info found  
    - *System message:* Internal company knowledge assistant with strict no-hallucination policy.  
    - *Inputs:* User chat input, vector search results, and memory context  
    - *Outputs:* Final chat answer  
    - *Potential issues:* Latency, incomplete or no matching data.

  - **Simple Memory**  
    - *Type:* LangChain Memory Buffer Window  
    - *Role:* Stores last 10 messages to maintain conversational context.  
    - *Inputs:* Conversation messages  
    - *Outputs:* Context for AI Agent  
    - *Potential issues:* Memory overflow, context loss over long conversations.

  - **Supabase Vector Store**  
    - *Type:* LangChain Vector Store (Supabase)  
    - *Role:* Retrieves top 20 most similar chunks from Supabase vector DB for the user query.  
    - *Configuration:* Retrieve mode as tool; table `documents`; topK=20  
    - *Inputs:* Query embedding from `Embeddings OpenAI1`  
    - *Outputs:* Retrieved matching document chunks  
    - *Potential issues:* Slow DB queries, missing documents.

  - **Embeddings OpenAI1**  
    - *Type:* LangChain Embeddings (OpenAI)  
    - *Role:* Converts user question text into vector embedding for similarity search.  
    - *Inputs:* User chat input text  
    - *Outputs:* Query embedding vector  
    - *Potential issues:* API limits, embedding accuracy.

  - **OpenAI Chat Model**  
    - *Type:* LangChain LLM Chat (OpenAI GPT-4o-mini)  
    - *Role:* Generates natural language answers using retrieved context and user question.  
    - *Inputs:* Retrieved chunks and user question  
    - *Outputs:* AI-generated answer text  
    - *Potential issues:* Model hallucination if context insufficient, latency.

---

### 3. Summary Table

| Node Name                       | Node Type                                | Functional Role                                  | Input Node(s)                     | Output Node(s)                        | Sticky Note                                                 |
|--------------------------------|-----------------------------------------|-------------------------------------------------|----------------------------------|-------------------------------------|-------------------------------------------------------------|
| Google Drive Trigger File Created | Google Drive Trigger                   | Watches Google Drive folder for new files       | None                             | Loop Over Items                      | üìÅ Data Processing from Google Drive: monitors folder, downloads files, extracts text |
| Loop Over Items                | Split In Batches                        | Processes each uploaded file one-by-one         | Google Drive Trigger File Created | Set File ID                        |                                                             |
| Set File ID                   | Set                                    | Extracts and stores Google Drive file ID        | Loop Over Items                  | Download File                      |                                                             |
| Download File                 | Google Drive                           | Downloads file, converts Google Docs to PDF     | Set File ID                     | Switch                            |                                                             |
| Switch                       | Switch                                 | Routes file processing by file MIME type        | Download File                   | Extract from PDF, Extract from CSV |                                                             |
| Extract from PDF              | Extract From File (PDF)                 | Extracts text from PDF file                       | Switch                         | Document Data                     |                                                             |
| Extract from CSV              | Extract From File (CSV)                 | Extracts text from CSV file                       | Switch                         | Document Data                     |                                                             |
| Document Data                | Set                                    | Wraps extracted text into JSON                    | Extract from PDF, Extract from CSV | Create Metadata Title & Description |                                                             |
| Create Metadata Title & Description | LangChain Chain LLM (Google Gemini) | Generates document title and description metadata | Document Data                 | Split into chunks                | üß† RAG Data Upload Pipeline: AI metadata and chunking pipeline |
| Structured Output Parser      | LangChain Output Parser                 | Parses metadata JSON from AI output               | Create Metadata Title & Description | Split into chunks                |                                                             |
| Split into chunks             | Code                                   | Splits document into chunks with overlap         | Create Metadata Title & Description | Split Out                      |                                                             |
| Split Out                    | Split Out                              | Converts chunks array into individual items       | Split into chunks              | Limit                           |                                                             |
| Limit                        | Limit                                  | Limits processing to first 20 chunks              | Split Out                     | Process Context                 | üìå Understanding the Limit Node: controls processing volume  |
| Process Context              | LangChain Chain LLM (Google Gemini)     | Enhances chunk context and clarity                 | Limit                         | Summarize                      |                                                             |
| Summarize                   | Summarize                             | Concatenates enhanced chunks with separator       | Process Context               | Character Text Splitter         |                                                             |
| Character Text Splitter      | LangChain Text Splitter (Character)     | Splits summarized text back into chunks           | Summarize                    | Default Data Loader             |                                                             |
| Default Data Loader          | LangChain Document Data Loader           | Wraps chunks with metadata for vector DB           | Character Text Splitter       | Embeddings OpenAI              |                                                             |
| Embeddings OpenAI            | LangChain Embeddings (OpenAI)            | Generates vector embeddings from text chunks       | Default Data Loader           | Add Data to Supabase Vector Store |                                                             |
| Add Data to Supabase Vector Store | LangChain Vector Store (Supabase)      | Inserts embeddings and metadata into Supabase DB   | Embeddings OpenAI             | None                          |                                                             |
| When chat message received   | LangChain Chat Trigger (Webhook)         | Receives user chat inputs                           | None                         | AI Agent                      | ü§ñ Chat Interface Workflow: listens for user chat input      |
| AI Agent                    | LangChain Agent                          | Orchestrates chat response with vector DB search   | When chat message received, OpenAI Chat Model, Supabase Vector Store, Simple Memory | None |                                                             |
| Simple Memory               | LangChain Memory Buffer Window            | Maintains conversation history                      | AI Agent                      | AI Agent                      |                                                             |
| Supabase Vector Store       | LangChain Vector Store (Supabase)          | Retrieves relevant document chunks for query       | Embeddings OpenAI1            | AI Agent                      |                                                             |
| Embeddings OpenAI1          | LangChain Embeddings (OpenAI)              | Embeds user query for vector similarity search      | When chat message received    | Supabase Vector Store          |                                                             |
| OpenAI Chat Model           | LangChain LLM Chat (OpenAI GPT-4o-mini)    | Generates natural language responses                 | Supabase Vector Store, When chat message received | AI Agent                      |                                                             |

---

### 4. Reproducing the Workflow from Scratch

1. **Create Google Drive Trigger File Created**  
   - Node Type: Google Drive Trigger  
   - Configure to watch folder by URL: `https://drive.google.com/drive/u/0/folders/1B-Wl-ktVFbTmX685DB978jNvs9Ihnxiv`  
   - Set trigger event: `fileCreated`  
   - Poll every minute  
   - Attach Google Drive OAuth2 credentials

2. **Add Loop Over Items**  
   - Node Type: Split In Batches  
   - Connect from Google Drive Trigger output  
   - Default batch size (process items one by one)  

3. **Add Set File ID**  
   - Node Type: Set  
   - Assign `file_id` = `{{$json.id}}` from incoming item  
   - Connect from Loop Over Items  

4. **Add Download File**  
   - Node Type: Google Drive  
   - Operation: Download  
   - File ID: `={{$('Set File ID').item.json.file_id}}`  
   - Enable Google file conversion for Google Docs ‚Üí PDF  
   - Attach Google Drive OAuth2 credentials  
   - Connect from Set File ID  

5. **Add Switch (File Type)**  
   - Node Type: Switch  
   - Condition: Check binary data MIME type (`{{$binary.data.mimeType}}`)  
   - Output 1: `application/pdf` ‚Üí PDF extraction  
   - Output 2: `text/csv` ‚Üí CSV extraction  
   - Connect from Download File  

6. **Add Extract from PDF**  
   - Node Type: Extract From File  
   - Operation: PDF extraction  
   - Connect from Switch output for PDFs  

7. **Add Extract from CSV**  
   - Node Type: Extract From File  
   - Default operation (CSV)  
   - Connect from Switch output for CSVs  

8. **Add Document Data Set**  
   - Node Type: Set  
   - Wrap extracted text in JSON under key `data` using expression:  
     `={"data": {{$json.text}}}`  
   - Connect from both Extract nodes  

9. **Add Create Metadata Title & Description**  
   - Node Type: LangChain Chain LLM (Google Gemini)  
   - Prompt: Instruct Gemini to create a metadata title and description from document text  
   - Input: Document Data JSON  
   - Attach Google Gemini API credentials  
   - Connect from Document Data  

10. **Add Structured Output Parser**  
    - Node Type: LangChain Output Parser  
    - Provide example JSON schema with `title` and `description`  
    - Connect from Create Metadata node  

11. **Add Split into chunks (Code node)**  
    - Node Type: Code (JavaScript)  
    - Paste provided chunking code to split text into ~1000 char chunks with 200 char overlap  
    - Input: Metadata node output document text  
    - Connect from Create Metadata Title & Description node  

12. **Add Split Out**  
    - Node Type: Split Out  
    - Field to split out: `chunks`  
    - Connect from Split into chunks  

13. **Add Limit**  
    - Node Type: Limit  
    - Max items: 20  
    - Connect from Split Out  

14. **Add Process Context (LangChain Chain LLM, Google Gemini)**  
    - Use prompt instructing to provide succinct context and fix incomplete chunks  
    - Inputs: Full document data and individual chunk text  
    - Connect from Limit  

15. **Add Summarize**  
    - Node Type: Summarize  
    - Fields to summarize: `text` field from Process Context output  
    - Separator: `###SPLIT###`  
    - Connect from Process Context  

16. **Add Character Text Splitter**  
    - Node Type: LangChain Text Splitter (Character)  
    - Separator: `###SPLIT###`  
    - Connect from Summarize  

17. **Add Default Data Loader**  
    - Node Type: LangChain Document Default Data Loader  
    - Metadata fields:  
      - `file_id` from `Set File ID`  
      - `title` and `description` from Metadata node output  
    - Input text: chunked text from Character Text Splitter  
    - Connect from Character Text Splitter  

18. **Add Embeddings OpenAI**  
    - Node Type: LangChain Embeddings (OpenAI)  
    - Attach OpenAI API credentials  
    - Connect from Default Data Loader  

19. **Add Add Data to Supabase Vector Store**  
    - Node Type: LangChain Vector Store (Supabase)  
    - Mode: Insert  
    - Table: `documents`  
    - Attach Supabase API credentials  
    - Connect from Embeddings OpenAI  

20. **Add When chat message received (Webhook Trigger)**  
    - Node Type: LangChain Chat Trigger  
    - Webhook ID: auto-generated or configured  
    - Connect to AI Agent  

21. **Add Embeddings OpenAI1**  
    - Node Type: LangChain Embeddings (OpenAI)  
    - Embed user chat input text  
    - Connect from When chat message received  

22. **Add Supabase Vector Store**  
    - Node Type: LangChain Vector Store (Supabase)  
    - Mode: Retrieve as tool  
    - Table: `documents`  
    - TopK: 20  
    - Connect from Embeddings OpenAI1  

23. **Add OpenAI Chat Model**  
    - Node Type: LangChain LLM Chat (OpenAI GPT-4o-mini)  
    - Attach OpenAI API credentials  
    - Connect from Supabase Vector Store  

24. **Add Simple Memory**  
    - Node Type: LangChain Memory Buffer Window  
    - Context window: 10 messages  
    - Connect memory to AI Agent  

25. **Add AI Agent**  
    - Node Type: LangChain Agent  
    - System message: Internal company knowledge assistant with no hallucination policy  
    - Connect inputs from:  
      - User chat input (When chat message received)  
      - Simple Memory  
      - OpenAI Chat Model  
      - Supabase Vector Store  
    - Outputs final chat response  

---

### 5. General Notes & Resources

| Note Content                                                                                                                                                                                                                                                                                            | Context or Link                                                                                      |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|
| **Workflow Author:** Billy Christi ‚Äî n8n Creator [https://n8n.io/creators/billy/](https://n8n.io/creators/billy/)                                                                                                                                                                                     | Credit and project origin                                                                           |
| The Supabase database requires a table `documents` with schema: <br>```sql<br>CREATE TABLE public.documents (<br>  id bigserial PRIMARY KEY,<br>  content text,<br>  metadata jsonb,<br>  embedding vector<br>);<br>```                                                                                     | Database setup requirement                                                                          |
| Required credentials: Google Drive OAuth2, Supabase API key & URL, OpenAI API key, Google Gemini API key                                                                                                                                                                                             | Credential setup                                                                                   |
| The workflow includes detailed sticky notes explaining each logical block, such as data ingestion, AI metadata generation, chunking, embedding, vector storage, and chat interface. Use these as visual guidance in n8n editor.                                                                          | Workflow documentation embedded as sticky notes                                                   |
| The chunking code prioritizes splitting at paragraph, sentence, then word level to maintain semantic coherence, with fallback hard splits to control chunk size.                                                                                                                                    | Chunking logic explanation                                                                          |

---

This document enables understanding, reproducing, and modifying the AI-Powered RAG Document Processing & Chatbot workflow integrating Google Drive, Supabase, OpenAI, and Google Gemini AI services. It anticipates potential failure points including API limits, file processing errors, and document parsing issues, providing a robust foundation for similar automation projects.