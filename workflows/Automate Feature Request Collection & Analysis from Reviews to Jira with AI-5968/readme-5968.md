Automate Feature Request Collection & Analysis from Reviews to Jira with AI

https://n8nworkflows.xyz/workflows/automate-feature-request-collection---analysis-from-reviews-to-jira-with-ai-5968


# Automate Feature Request Collection & Analysis from Reviews to Jira with AI

### 1. Workflow Overview

This workflow automates the collection, analysis, and tracking of feature requests extracted from user reviews on external review sites (e.g., Trustpilot). Its primary target use case is product management teams seeking to gather real user feedback and convert it directly into actionable Jira tickets without manual copy-pasting or analysis.

The workflow is divided into three main logical blocks:

- **1.1 Start and Target Setup**: Provides manual triggering and editable input for the review site URL to initiate the workflow.

- **1.2 Scrape and Structure User Reviews**: Uses an AI-powered agent combined with a Bright Data MCP scraper and OpenAI models to extract, parse, and optionally analyze user reviews, producing a structured list of feature requests.

- **1.3 Convert Reviews into Jira Tasks**: Processes each individual review and creates a corresponding Jira issue for tracking and prioritization.

---

### 2. Block-by-Block Analysis

#### 1.1 Start and Target Setup

**Overview:**  
This block initializes the workflow by allowing manual execution and setting the URL of the target review page dynamically, enabling easy changes without modifying code.

**Nodes Involved:**  
- üîò Start Manual Execution  
- üñäÔ∏è Edit Target Site URL

**Node Details:**

- **üîò Start Manual Execution**  
  - *Type & Role:* Manual Trigger node; starts workflow execution on-demand.  
  - *Configuration:* No parameters; simply triggers workflow when clicked.  
  - *Inputs/Outputs:* No input; output triggers next node.  
  - *Edge Cases:* None expected; failure only if n8n runtime issues occur.  
  - *Notes:* Enables manual testing or scheduled runs by replacing with other triggers.

- **üñäÔ∏è Edit Target Site URL**  
  - *Type & Role:* Set node; assigns the URL of the review site to a variable.  
  - *Configuration:* Sets a string field named `URL` to `https://www.trustpilot.com/review/clickup.com` (editable).  
  - *Inputs/Outputs:* Input from manual trigger; outputs JSON with URL.  
  - *Edge Cases:* Incorrect or inaccessible URLs lead to scraping failure downstream.  
  - *Notes:* Designed for easy URL changes by non-technical users.

---

#### 1.2 Scrape and Structure User Reviews

**Overview:**  
This core block uses a LangChain Agent integrated with Bright Data MCP scraper and OpenAI models to visit the review site, extract reviews specifically mentioning feature requests, parse their content into structured JSON, and optionally perform AI-driven classification or summarization.

**Nodes Involved:**  
- ü§ñ Scrape Reviews using Agent  
- üåê Bright Data MCP Scraper  
- üß† OpenAI Chat Model (auxiliary, optional)  
- Auto-fixing Output Parser  
- Structured Output Parser  
- OpenAI Chat Model (separate usage)

**Node Details:**

- **ü§ñ Scrape Reviews using Agent**  
  - *Type & Role:* LangChain Agent node; orchestrates scraping and AI to extract review data.  
  - *Configuration:* Prompt instructs extraction of review text, title, date, and username from given URL, filtering for functionality requests aimed at improving user experience.  
  - *Inputs/Outputs:* Input URL from previous Set node; outputs structured review objects.  
  - *Edge Cases:* Failures include scraping blocks, malformed page content, or unexpected HTML changes. AI may misinterpret or miss relevant reviews.  
  - *Integration:* Calls Bright Data MCP Scraper as a tool for scraping. Also connected to OpenAI Chat Model for language understanding.

- **üåê Bright Data MCP Scraper**  
  - *Type & Role:* External scraping tool node; executes scraping as per agent instructions using Bright Data's proxy infrastructure.  
  - *Configuration:* Uses "scrape_as_markdown" tool with dynamic parameters generated by AI.  
  - *Credentials:* Requires MCP Client API credentials.  
  - *Edge Cases:* Network or proxy failures, rate limits, or data structure changes on target site.

- **üß† OpenAI Chat Model (Agent Support)**  
  - *Type & Role:* OpenAI GPT model (gpt-4o-mini); used by agent for NLP tasks like understanding and parsing reviews.  
  - *Credentials:* OpenAI API key required.  
  - *Edge Cases:* API rate limits, network failures, or unexpected model errors.

- **Auto-fixing Output Parser**  
  - *Type & Role:* LangChain output parser; automatically corrects and formats agent outputs into valid JSON structures.  
  - *Edge Cases:* Parsing errors if output is too noisy or incomplete.

- **Structured Output Parser**  
  - *Type & Role:* Enforces JSON schema compliance on parsed reviews to ensure they include required fields like `title`, `url`, `date`, `username`, and `review_text`.  
  - *Edge Cases:* Schema mismatches or missing fields cause downstream errors.

- **OpenAI Chat Model (Optional Analysis)**  
  - *Role:* Can be used optionally to classify reviews by category or summarize them, though not mandatory in this workflow configuration.

---

#### 1.3 Convert Reviews into Jira Tasks

**Overview:**  
This final block processes each structured review individually, formatting it and creating a Jira ticket per feature request, enabling product teams to track user feedback as actionable items.

**Nodes Involved:**  
- üß© Format Individual Reviews  
- üóÇÔ∏è Create Feature Ticket in Jira

**Node Details:**

- **üß© Format Individual Reviews**  
  - *Type & Role:* Code (Function) node; splits the array of reviews into individual items to enable one Jira ticket per review.  
  - *Configuration:* JavaScript code extracts each review object from the array and returns it as separate workflow items.  
  - *Inputs/Outputs:* Input is array of reviews; output is one item per review JSON.  
  - *Edge Cases:* If input is empty or malformed, no tickets generated.

- **üóÇÔ∏è Create Feature Ticket in Jira**  
  - *Type & Role:* Jira node; creates a new issue in specified Jira project for each review.  
  - *Configuration:*  
    - Uses dynamic summary and description fields populated from review data (title, URL, date, username, and review text).  
    - Project and Issue type selected via list mode (requires user setup).  
  - *Credentials:* Jira OAuth2 or API token credentials required.  
  - *Inputs/Outputs:* Input is single review per execution; output is Jira issue creation response.  
  - *Edge Cases:* Authentication failures, API quota limits, Jira field validation errors, or connectivity issues.

---

### 3. Summary Table

| Node Name                   | Node Type                             | Functional Role                            | Input Node(s)                | Output Node(s)                  | Sticky Note                                                                                       |
|-----------------------------|-------------------------------------|--------------------------------------------|-----------------------------|-------------------------------|-------------------------------------------------------------------------------------------------|
| üîò Start Manual Execution    | Manual Trigger                      | Workflow start trigger                     | ‚Äî                           | üñäÔ∏è Edit Target Site URL         | Enables manual workflow execution to test or run on demand.                                     |
| üñäÔ∏è Edit Target Site URL      | Set                                | Defines the review site URL input          | üîò Start Manual Execution    | ü§ñ Scrape Reviews using Agent  | Editable URL input for flexible target review site configuration.                               |
| ü§ñ Scrape Reviews using Agent | LangChain Agent                    | Scrapes and extracts reviews via AI       | üñäÔ∏è Edit Target Site URL, MCP Scraper, OpenAI Chat Model | üß© Format Individual Reviews     | Uses Bright Data MCP scraper and OpenAI to collect and parse feature-request reviews.           |
| üåê Bright Data MCP Scraper   | Bright Data MCP Integration Tool   | Executes scraping on target website        | ‚Äî                           | ü§ñ Scrape Reviews using Agent  | Uses Bright Data proxies for robust scraping behind the scenes.                                 |
| üß† OpenAI Chat Model         | OpenAI GPT Model                   | Supports AI tasks in review extraction     | ‚Äî                           | ü§ñ Scrape Reviews using Agent  | Optional AI processing layer for understanding review content.                                 |
| Auto-fixing Output Parser    | LangChain Output Parser            | Cleans and corrects AI output format       | Structured Output Parser, OpenAI Chat Model | ü§ñ Scrape Reviews using Agent  | Ensures scraped data is well-structured and parseable JSON.                                    |
| Structured Output Parser     | LangChain Structured Parser       | Enforces JSON schema for extracted reviews| ‚Äî                           | Auto-fixing Output Parser      | Validates structure of extracted review objects.                                               |
| üß© Format Individual Reviews | Code (Function)                    | Splits review array into individual items  | ü§ñ Scrape Reviews using Agent| üóÇÔ∏è Create Feature Ticket in Jira| Splits multi-review output into single review items for Jira ticket creation.                  |
| üóÇÔ∏è Create Feature Ticket in Jira | Jira Issue Creation             | Creates Jira tickets for each review       | üß© Format Individual Reviews | ‚Äî                             | Converts each feature request into a Jira issue with relevant details.                         |
| Sticky Note                  | Sticky Note                       | Documentation and notes                     | ‚Äî                           | ‚Äî                             | Multiple sticky notes provide detailed guidance for sections and tips (see notes below).       |

---

### 4. Reproducing the Workflow from Scratch

1. **Create a Manual Trigger Node:**  
   - Name it "üîò Start Manual Execution". No parameters needed. This will allow manual start of the workflow.

2. **Add a Set Node:**  
   - Name it "üñäÔ∏è Edit Target Site URL".  
   - Add a string field named `URL`. Set its default value to `https://www.trustpilot.com/review/clickup.com`. This field is editable to specify the target review page.  
   - Connect the Manual Trigger node output to this node input.

3. **Add a Bright Data MCP Scraper Node:**  
   - Name it "üåê Bright Data MCP Scraper".  
   - Select the tool "scrape_as_markdown".  
   - For tool parameters, leave it empty or dynamically set as per scraping needs if integrating with AI node later.  
   - Under Credentials, add your Bright Data MCP Client API credentials.  
   - This node will be used as an AI tool subcomponent by the LangChain Agent (no direct connections here).

4. **Add an OpenAI Chat Model Node:**  
   - Name it "üß† OpenAI Chat Model".  
   - Set model to "gpt-4o-mini" (or equivalent GPT-4 capable model).  
   - Provide valid OpenAI API credentials.  
   - This node supports the LangChain Agent with language understanding.

5. **Add a Structured Output Parser Node:**  
   - Name it "Structured Output Parser".  
   - Configure JSON schema example to include fields: `title`, `url`, `date`, `username`, and `review_text`.  
   - This node validates the data structure of scraped reviews.

6. **Add an Auto-fixing Output Parser Node:**  
   - Name it "Auto-fixing Output Parser".  
   - No special configuration; it filters and fixes AI output to produce valid JSON.

7. **Add a LangChain Agent Node:**  
   - Name it "ü§ñ Scrape Reviews using Agent".  
   - Set prompt to:  
     ```
     Extract review text, title, date and username (if any) from the following url. Make sure to extract only those reviews that are asking for functionality for better user experience.

     URL: {{ $json.URL }}
     ```  
   - Configure agent to use the Bright Data MCP Scraper as a tool.  
   - Link the OpenAI Chat Model node as its language model.  
   - Link the Structured Output Parser and Auto-fixing Output Parser for output parsing.  
   - Connect input from the "üñäÔ∏è Edit Target Site URL" node.

8. **Add a Code Node:**  
   - Name it "üß© Format Individual Reviews".  
   - Configure the JavaScript code to split the array of reviews into individual items:  
     ```js
     const reviews = items[0].json.output;
     return reviews.map(review => ({ json: review }));
     ```  
   - Connect input from the LangChain Agent node.

9. **Add a Jira Node:**  
   - Name it "üóÇÔ∏è Create Feature Ticket in Jira".  
   - Configure project and issue type by selecting from your Jira instance.  
   - Set summary to:  
     ```
     Below are the feature requests from the users on trustpilot:

     Title: {{ $json.title }}
     URL: {{ $json.url }}
     Date: {{ $json.date }}
     Username: {{ $json.username }}
     Feature request: {{ $json.review_text }}
     ```  
   - Provide Jira OAuth2 or API token credentials.  
   - Connect input from the Code node.

10. **Connect all nodes in sequence:**  
    - Manual Trigger ‚Üí Set URL ‚Üí LangChain Agent ‚Üí Format Individual Reviews ‚Üí Create Feature Ticket in Jira.

11. **(Optional) Add Sticky Notes:**  
    - Create sticky notes with the content from the original workflow for documentation and clarity for users.

---

### 5. General Notes & Resources

| Note Content                                                                                                                                                                                                                         | Context or Link                                                                                          |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| Workflow automates collection of feature requests from review sites using AI and proxies, pushing to Jira for product management tracking.                                                                                          | Workflow purpose overview.                                                                               |
| Manual trigger allows easy testing and dynamic URL input avoids hardcoding, suitable for non-developers.                                                                                                                            | Usability and flexibility notes.                                                                        |
| Bright Data MCP scraper handles proxy-based scraping, improving reliability and bypassing anti-bot protections.                                                                                                                    | https://get.brightdata.com/1tndi4600b25 (affiliate link)                                                |
| OpenAI GPT-4 model used for natural language understanding and parsing of reviews, enabling extraction of relevant feature requests.                                                                                               | Requires OpenAI API credentials.                                                                         |
| Jira integration supports direct creation of issues from feedback, streamlining product team workflows.                                                                                                                             | Jira OAuth2 or API token credentials needed.                                                            |
| For support or more resources, contact Yaron at Yaron@nofluff.online. Additional tutorials and tips available on YouTube at https://www.youtube.com/@YaronBeen/videos and LinkedIn at https://www.linkedin.com/in/yaronbeen/.           | Contact and learning resources.                                                                          |

---

**Disclaimer:** The text provided originates exclusively from an automated workflow created with n8n, a tool for integration and automation. This processing strictly adheres to current content policies and contains no illegal, offensive, or protected material. All handled data is legal and public.